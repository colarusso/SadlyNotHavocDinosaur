<!DOCTYPE html>
<HTML><HEAD>

  <!-- Set base for this page equal to domain root -->
  <base href="../../">

  <!-- Page-specific metadata -->
  <title>I'm Sorry, Dave Can't Do That: Use the text of an email to draft a polite reply declining any request(s)</title>
  <meta property="og:type" content="website"/>
  <meta property="og:publish_date" content="2024-01-18T00:00:00-0500"/>
	<meta property="og:title" content="I'm Sorry, Dave Can't Do That: Use the text of an email to draft a polite reply declining any request(s)"/>
	<meta property="og:description" content="With apologies to Kubrick and Clarke, at least I can say I held out two full days before alluding to a killer AI. That's also how long I resisted sharing a use case in which we use an LLM to help write something. There's a great deal to be said about authorship in the age of ChatGPT, and perhaps we'll explore this more in future posts. For the moment, however, let me provide a framing I find useful. It starts by recognizing that context matters and that writing itself is not one task. The production of written work involves the application of multiple overlapping tasks. Consider the traditional roles found in a newsroom (e.g., editors in chief, assignment editors, writers, fact checkers, copy editors, and the like). When delegating any of these tasks, to a human or otherwise, it is important to have in mind what role(s) we are delegating and why. Putting one's name to a document means different things in different contexts. Just ask the paralegal who writes all their partner's &quote;first drafts.&quote; For instructors worried about the use of AI by their students, I suggest they name the role(s) an assignment is looking to assess. This allows the instructor and student to properly evaluate whether or not the use of this or that tool is acceptable. If handwriting is among the matters being assessed, a word processor is out. Copy editing? This may or may not exclude the use of spell check. What about grammar check? If, however, there is no instructor, and the question is left to us alone, we have to be honest with ourselves about the job at hand. "/>
	<meta property="og:image" content="images/50-days/robo_shrug_square.png"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-ST9X6H808L"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-ST9X6H808L');
  </script>

  <!-- Metadata for mobile -->
	<meta http-equiv="Content-type" content="text/html;charset=UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
  <meta name="apple-mobile-web-app-capable" content="no" />
  <link rel="apple-touch-icon" href="images/comic.png"/>

  <!-- JS & style -->
	<link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
	<link rel="stylesheet" type="text/css" href="css/style.css">
  <script src="js/functions.js"></script>
  <script src="js/spin.js"></script>

  <script id="MathJax-script" async src="js/mathjax/tex-mml-chtml.js"></script>

  <link rel="stylesheet" href="css/prism.css" data-noprefix="">
  <script type="text/javascript" src="js/prism.js"></script>

  <!--<link rel="stylesheet" type="text/css" href="css/green-audio-player.css">
  <script src="js/green-audio-player.js"></script>-->
  
  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="Sadly Not, Havoc Dinosaur" href="https://sadlynothavocdinosaur.com/feed.xml" />

</HEAD>
<BODY BGCOLOR="#ffffff" BACKGROUND="" MARGINWIDTH="0" MARGINHEIGHT="0">

<!-- Title and search -->
<div class="title_bar">
  <div class="home">
    <a href="./" tabindex="1"><img src="images/home.png" class="home_btn"></a>
  </div>  
  <div class="search">
    <a href="javascript:show_search();" tabindex="3"><img src="images/search.png" class="search_btn"></a>
    <input id="query" type="text" tabindex="2"/>
  </div>
  <span id="title"><a href="./" class="title_home">Sadly Not, Havoc Dinosaur</a></span>
</div>

<div class="content">
  <!-- START PAGE CONTENT -->
  
  <div id="page">
  <!-- 
    =================================================
    
                      INTRODUCTION

    =================================================
  -->
  <h1 class="post_title_01">I'm Sorry, Dave Can't Do That</i></h1>
  <div class="post_title_02">Use the text of an email to draft a polite reply declining any request(s)</div>
  <div class="featured_img_right">
    <!--<div class="audio_container_container" style="display:show;">
      <div class="audio_container">
        <b>Hear the author read <i>TK</i></b>
        <div class="gap-example player-accessible">
          <audio>
              <source src="mp3s/title.mp3" type="audio/mpeg">
          </audio>
        </div>
        <span class="playback">
          Speed: <a href="javascript:void('')" onClick="set_speed(0.5)" class="playback" id="pb05">0.5x</a> &bull;
                  <a href="javascript:void('')" onClick="set_speed(1)" class="playback" id="pb10" style="font-weight:900;">1x</a> &bull;
                  <a href="javascript:void('')" onClick="set_speed(1.5)" class="playback" id="pb15">1.5x</a> &bull;
                  <a href="javascript:void('')" onClick="set_speed(2)" class="playback" id="pb20">2x</a> &bull;
                  <a href="javascript:void('')" onClick="set_speed(3)" class="playback" id="pb30">3x</a>
        </span>
      </div>
    </div>-->
    <a href="images/50-days/robo_shrug.png"><img src="images/50-days/robo_shrug.png" ALT="Image of an apologetic robot shrugging in front of a computer at a desk." class="list_img_file"/></a>
    <div class="caption">
      Sorry, not sorry, latent space "photography" by <a href="https://mastodon.social/@Colarusso" target="_blank" class="captionlnk">Colarusso</a>
    </div>
  </div>
  <p class="post_p">
    <a href="https://mastodon.social/@Colarusso" target="_blank" class="body_links"><img src="images/colarusso.jpg" class="headshot_small" alt="Headshot of the author, Colarusso." style="margin-top: 7px;"/></a>
    David Colaursso<br><span class="post_date">Co-director, Suffolk's <a href="https://suffolklitlab.org/" target="_blank" class="captionlnk">Legal Innovation &amp; Tech Lab</a></span>
  </p>
  <p><i>This is <b>the 3rd</b> post in my series <a href="posts/50-days-of-lit-prompts">50 Days of LIT Prompts</i></a>.</p>
	<p>
    With apologies to Kubrick and Clarke, at least I can say I held out two full days before alluding to a <a href="https://www.youtube.com/watch?v=Wy4EfdnMZ5g" target="_blank">killer AI</a>. That's also how long I resisted sharing a use case in which we use an LLM to help write something. There's a great deal to be said about authorship in the age of ChatGPT, and perhaps we'll explore this more in future posts. For the moment, however, let me provide a framing I find useful. It starts by recognizing that context matters and that writing itself is not one task. The production of written work involves the application of multiple overlapping tasks. Consider the traditional roles found in a newsroom (e.g., editors in chief, assignment editors, writers, fact checkers, copy editors, and the like). When delegating any of these tasks, to a human or otherwise, it is important to have in mind what role(s) we are delegating and why. Putting one's name to a document means different things in different contexts. Just ask the paralegal who writes all their partner's "first drafts." For instructors worried about the use of AI by their students, I suggest they name the role(s) an assignment is looking to assess. This allows the instructor and student to properly evaluate whether or not the use of this or that tool is acceptable. If handwriting is among the matters being assessed, a word processor is out. Copy editing? This may or may not exclude the use of spell check. What about grammar check? If, however, there is no instructor, and the question is left to us alone, we have to be honest with ourselves about the job at hand. 
  </p>
  <p>
    Today we'll be using our LLM to respond to unwanted emails, some of which I suspect may themselves have been written by AI. I have in mind a particular class of emails for which I almost always answer, "no." For me, it's unsolicited emails from strangers who are trying to sell me something or ask for something but not in a spam sort of way. The point is, I want to acknowledge the email and politely decline, but I really don't want to take too much time struggling over what to say. When we're done here, you'll be able to select the text of an email (assuming you're using a web interface), click a button, and have a draft email declining any request(s) in your clipboard ready to paste into a reply. This is a very narrow use case and probably not the type of writing Ted Chiang had in mind when he <a href="https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web" target="_blank">the following observation</a>: 
  </p>
  <blockquote>
    Some might say that the output of large language models doesn't look all that different from a human writer's first draft, but, again, I think this is a superficial resemblance. Your first draft isn't an unoriginal idea expressed clearly; it's an original idea expressed poorly, and it is accompanied by your amorphous dissatisfaction, your awareness of the distance between what it says and what you want it to say. That's what directs you during rewriting, and that's one of the things lacking when you start with text generated by an A.I.
  </blockquote>
  <p>    
    Sometimes writing doesn't need to express original ideas, and sometimes you aren't playing the role of a Writer with a capital W. Sometimes you just need to solve the blank page problem. Today's template will do that, but we need to stay vigilant and always be honest with ourselves about the goals of our writing. I suspect Chaing confronted with this narrowing might ask us to consider, not only what writing does for the writer, but what a writer owes their audience. What roles have we reserved for ourselves? Is this "division" of labor appropriate given the context? Here's a thought experiment, how would you feel about having a personal assistant ghostwriting your emails, prepping a first draft? Would you tell people? Why or why not? 
  </p>
  <p>Of course, it helps when answering such questions if we understand exactly what it is our tools do. Time for our micro-lesson, followed immediately by our prompt work.</p>
  <b><a name="neuron" href="posts/decline-requests/#neuron" class="anchor" alt="deep link to this section"></a>Artificial Neurons</b>
  <p>
    <a href="posts/define-words">Yesterday</a>, we took our first step towards understanding how LLMs are made. This involved learning about <a href="posts/define-words/#logistic">logistic regression</a>, and as we noted then, <b>yes, there's going to be some math, but there won't be a quiz, and I give you permission to skim over things if you like. That being said, if you can get through this, the payoff will be big.</b> Like, "understand what this AI thing actually is" big. 
  </p>
  <p>
    You'll remember that our regression was able to take in a measure of snowfall and predict the odds class would be canceled. What if we wanted to consider more than just how much snow fell? It turns out that all we have to do is add two numbers for each new inputthe new input we want to consider and some "weight" to multiply by that input. This new weight is analogous to yesterday's <i>B<sub>1</sub></i> which we multiplied by the value of <i>x</i> (our snowfall). Remember, this was found by fiddling with values untill our curve matched the data. Mathematically, all this means is that we add the new weight, <i>B<sub>2</sub></i>, and the new input <i>x<sub>2</sub></i> to the equation from yesterday.
  </p>

  <p>\[y = {{1} \over {1 + e^{-(B_0 + B_1路x + B_2路x_2)}}}\]<p>

  <p>And we can keep doing this for as many new inputs as we like.</p>

  <p>\[y = {{1} \over {1 + e^{-(B_0 + B_1路x + B_2路x_2 + B_3路x_3 + B_4路x_4 . . . + B_n路x_n)}}}\]<p>

  <p>
    In this way, we can account for things like temperature and windspeed when predicting whether or not class will be canceled. Of course, we get the values of <i>B<sub>0</sub></i> through <i>B<sub>n</sub></i> by fiddling with those values until our graph "fits." It's just like yesterday except there are now more values (dimensions) to fiddle with. We put in values for <i>x<sub></sub></i> through <i>x<sub>n</sub></i> and get out a value for <i>y</i> which we are reading as our prediction for whether school will close.
  </p>
  <p>Now, if we take our regression and lay it out like so... and set this next to a neuron...</p>
  <div class="featured_img_center">
    <a href="images/50-days/neurons.png"><img src="images/50-days/neurons.png" ALT="Our artificl neuron next to a drawing of a real neuron." class="list_img_file"/></a>
    <div class="caption">
      Left: our regression. Right: <a href="https://commons.wikimedia.org/wiki/File:Components_of_neuron.jpg" target="_blank" class="captionlnk">Components of a neuron</a>
    </div>
  </div>
  <p>
    We can start to see how one might analogize the two. Let's call our construction an artificial neuron. It takes in inputs and sums them up such that different inputs trigger different outputs. This very roughly acts "like" a neuron which takes inputs in through the dendrites, "sums" these within the cell body, and outputs a signal via the axon. This the point where I emphasize the fact that artificial neurons are at best cartoon versions of real neurons, and also, I'm glossing over a lot of nuance (e.g., most folks wouldn't want to say a neuron is the same as a logistic regression; it's more of a process than the final function and weights; also, folks don't tend to use a sigmoid anymore, etc.). I think the above, however, will serve as a good foundation for what follows.
  </p>
  <p>
    We've come a long way from predicting snow days. Tomorrow, we'll deal with artificial neural networks, predicting words, can't be that far off. Until then, <b>let's build something!</b>
  </p>
  <!-- END INTRO -->
  <p>
    We'll do our building in the LIT Prompts extension. If you aren't familiar with the extension, don't worry. We'll walk you through setting things up before we start building. If you have used the LIT Prompts extension before, skip to <a href="posts/decline-requests/#template">The Prompt Pattern (Template)</a>.
  </p>
  <h3>Up Next</h3>
  <ul>
    <li><a href="posts/decline-requests/#setup" onClick="expand_setup();">Setup LIT Prompts</a></li>
    <ul>
      <li><a href="posts/decline-requests/#install" onClick="expand_setup();">Install the extension</a></li>
      <li><a href="posts/decline-requests/#point" onClick="expand_setup();">Point it at an API</a></li>
    </ul>
    <li><a href="posts/decline-requests/#template">The Prompt Pattern (Template)</a></li>
    <li><a href="posts/decline-requests/#tires">Kick the Tires</a></li>
    <li><a href="posts/decline-requests/#references">TL;DR References</a></li>
  </ul>
  <p>
    <b>Questions or comments?</b> I'm on Mastodon <a href="https://mastodon.social/@Colarusso" target="_blank">@Colarusso@mastodon.social</a>
  </p>
  <!-- 
    =================================================
    
                   Setup LIT Prompts

    =================================================
  --> 
  <hr>
  <h2><a name="setup" href="posts/decline-requests/#setup" onClick="expand_setup();" class="anchor" alt="deep link to this section"></a>Setup LIT Prompts </h2>
  <div id="expand_setup" style="text-align: left;display:none;font-size: small;">
    <a href="javascript:expand_setup();" style="text-decoration: none;">&#9658; Expand</a>
  </div>
  <div id="collapse_setup" style="text-align: left;font-size: small;">
    <a href="javascript:collapse_setup();" style="text-decoration: none;">&#9660; Collapse</a>
  </div>
  <div id="setup_extension">
    <div class="list_vid">
      <iframe class="embed_vid" src="https://www.youtube-nocookie.com/embed/Ql8aXGvLBGU" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe>
      <div class="caption">
        7 min intro video
      </div>
    </div>
    <p>
      <i><b>LIT Prompts</b></i> is a browser extension built at Suffolk University Law School's <a href="https://suffolklitlab.org/" target="_blank">Legal Innovation and Technology Lab</a> to help folks explore the use of <a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank">Large Language Models</a> (LLMs) and <a href="https://en.wikipedia.org/wiki/Prompt_engineering" target="_blank">prompt engineering</a>. LLMs are sentence completion machines, and prompts are the text upon which they build. Feed an LLM a prompt, and it will return a plausible-sounding follow-up (e.g., "Four score and seven..." might return "years ago our fathers brought forth..."). LIT Prompts lets users create and save prompt templates based on data from an active browser window (e.g., selected text or the whole text of a webpage) along with text from a user. Below we'll walk through a specific example. 
    </p>
    <p>
      To get started, follow <b>the first four minutes</b> of the intro video or the steps outlined below. <i>Note: The video only shows Firefox, but once you've installed the extension, the steps are the same.</i>
    </p>
    <h3><a name="install" href="posts/decline-requests/#install" class="anchor" alt="deep link to this section"></a>Install the extension</h3>
    <p>Follow the links for your browser.</p>
    <ul>
      <li>
        <b>Firefox:</b> (1) visit the extension's <a href="https://addons.mozilla.org/en-US/firefox/addon/lit-prompts/" target="_blank">add-ons page</a>; (2) click "Add to Firefox;" and (3) grant permissions.
      </li>
      <li>
        <b>Chrome:</b>  (1) visit the extension's <a href="https://chromewebstore.google.com/detail/lit-prompts/hfeojjmldhebkeknfapoghcohkhffcmp" target="_blank">web store page</a>; (2) click "Add to Chrome;" and (3) review permissions / "Add extension."
      </li>
    </ul>
    <p>
      If you don't have Firefox, you can <a href="https://www.mozilla.org/en-US/firefox/new/" target="_blank">download it here</a>. Would you rather use Chrome? <a href="https://www.google.com/chrome/" target="_blank">Download it here</a>.
    </p>
    <h3><a name="point" href="posts/decline-requests/#point" class="anchor" alt="deep link to this section"></a>Point it at an API</h3>
    <p>
      Here we'll walk through how to use an LLM provided by OpenAI, but you don't have to use their offering. If you're interested in alternatives, you can find them <a href="https://github.com/SuffolkLITLab/prompts/tree/main#openai-compatible-api-integration" target="_blank">here</a>. You can even run your LLM locally, avoiding the need to share your prompts with a third-party. If you need an OpenAI account, you can <a href="https://platform.openai.com/signup" target="_blank">create one here</a>. Note: when you create a new OpenAI account you are given a limited amount of free API credits. If you created an account some time ago, however, these may have expired. If your credits have expired, you will need to enter a <a href="https://platform.openai.com/account/billing/overview" target="_blank">billing method</a> before you can use the API. You can check the state of any credits <a href="https://platform.openai.com/usage" target="_blank">here</a>. 
    </p>
    <p>
      Login to <a href="https://openai.com/" target="_blank">OpenAI</a>, and navigate to the <a href="https://platform.openai.com/docs/" target="_blank">API documentation</a>. 
    </p>
    <div class="featured_img_center">
      <a href="images/50-days/OpenAI_keys.png"><img src="images/50-days/OpenAI_keys.png" ALT="Screenshot of the OpenAI API Keys page showing where to click to create a new key." class="list_img_file" style="border: 1px solid #a5a5a5;"/></a>
    </div>
    <p>Once you are looking at the API docs, follow the steps outlined in the image above. That is:
    <ol>
      <li>Select "API keys" from the left menu</li>
      <li>Click "+ Create new secret key"</li>
    </ol>
    <hr>
    <p>
      On LIT Prompt's <i>Templates & Settings</i> screen, set your API Base to <code>https://api.openai.com/v1/chat/completions</code> and your API Key equal to the value you got above after clicking "+ Create new secret key".  You get there by clicking the <i>Templates & Settings</i> button in the extension's popup:
    </p>
    <ol>
      <li>open the extension</li>
      <li>click on  <i>Templates & Settings</i></li>
      <li>enter the API Base and Key (under the section <i>OpenAI-Compatible API Integration</i>)</li>
    </ol>
    <div class="featured_img_center">
      <a href="images/50-days/popup.png"><img src="images/50-days/popup.png" ALT="Screenshot of the LIT Prompts extension popup." class="list_img_file" style="border: 1px solid #a5a5a5;"/></a>
    </div>
    <p>
      Once those two bits of information (the API Base and Key) are in place, you're good to go. Now you can edit, create, and run prompt templates. Just open the LIT Prompts extension, and click one of the options. I suggest, however, that you read through the <i>Templates and Settings</i> screen to get oriented. You might even try out a few of the preloaded prompt templates. This will let you jump right in and get your hands dirty in the next section. 
    </p>
    <div class="featured_img_center">
      <a href="images/50-days/credentials.png"><img src="images/50-days/credentials.png" ALT="Screenshot of the LIT Prompts extension popup." class="list_img_file" style="border: 1px solid #a5a5a5;"/></a>
    </div>
    <p>
      <span style="background:yellow;">If you receive an error when trying to run a template after entering your Base and Key, and you are using OpenAI, make sure to check the state of any credits <a href="https://platform.openai.com/usage" target="_blank">here</a>. If you don't have any credits, you will need a billing method on file.</span>
    </p>
    <p>
      <i>If you found this hard to follow, consider following along with the first four minutes of the video <a href="posts/decline-requests/#setup">above</a>. It covers the same content. It focuses on Firefox, but once you've installed the extension, the steps are the same.</i>
    </p>
  </div>
 
  <!-- 
    =================================================
    
                   Write Your Template

    =================================================
  --> 
  <hr>
  <h2><a name="template" href="posts/decline-requests/#template" class="anchor" alt="deep link to this section"></a>The Prompt Pattern (Template)</h2>

  <div class="featured_img_right">
    <a href="images/boxquote.png"><img src="images/boxquote.png" ALT="A slide showing the Georeg Box quote: All models are wrong, but some models are useful." class="list_img_file"/></a>
    <div class="caption">
      Maps are models; they don't show everything. That's okay as long as you don't confuse the map for the territory.
    </div>
  </div>

  <p>
    When crafting a LIT Prompts template, we use a mix of plain language and variable placeholders. Specifically, you can use double curly brackets to encase predefined variables. If the text between the brackets matches one of our predefined variable names, that section of text will be replaced with the variable's value. Today we'll be using the <code>{{highlighted}}</code> variable. See the extension's <a href="https://github.com/SuffolkLITLab/prompts#prompt-templates" target="_blank">documentation</a>. 
  </p>
  <p>
    The <code>{{highlighted}}</code> variable contains any text you have highlighted/selected in the active browser tab when you open the extension. Like yesterday, this prompt pattern is pretty straight forward. Highlight the text of an email, and run the template. The LLM will generate a draft reply declining any request(s) and place it in your clipboard. To accomplish this last part be sure to set output to "Screen + clipboard."
  </p>
  <p> 
    It's worth taking a moment to consider one very important difference between this prompt template and those which have come before. Here you are potentially highlighting sensitive or otherwise private data. So, you need to think carefully about the particulars of your situation. For example, if you're <a href="https://github.com/SuffolkLITLab/prompts#using-lm-studio-with-lit-prompts" target="_blank">running LM Studio locally</a> then there isn't much to consider as the information won't leave your computer. However, if you're using some other API provider, you will be sending them the contents of anything you select. One thing you have going in your favor is that as an API user you may be subject to special terms that better protect your privacy. For example, as of this writing, users of OpenAI's API were subject to a different set of terms than users of ChatGPT. Namely, they are subject to the <a href="https://openai.com/policies/business-terms" target="_blank">Business Terms</a> which importantly preclude the use of your data for training purposes. This is important because if your data is being used to train an LLM it may one day come out the other end. 
  </p>
  <p>Here's the template text.</p>
  <!-- 
    #########################
    #########################
    #####   start code   ####
    #########################
    #########################
  -->
  <section class="line-numbers">
    <pre class="language-xxx" style="white-space:pre-wrap;"><code>{{highlighted}}

---

For the above email or email thread, draft a brief professional reply politely declining its request. Keep the email super short while being responsive to the specific ask(s).

</code></pre>
  </section>
  <!-- 
    #########################
    #########################
    #####    end code    ####
    #########################
    #########################
  -->
  <p>And here are the template's parameters:</p>
  <ul>
      <li><b>Output Type:</b> <code>LLM</code>. This choice means that we'll "run" the template through an LLM (i.e., this will ping an LLM and return a result). Alternatively, we could have chosen  "Prompt," in which case the extension would return the text of the completed template. </li>
      <li><b>Model:</b> <code>gpt-3.5-turbo-16k</code>. This input specifies what model we should use when running the prompt. Available models differ based on your API provider. See e.g., <a href="https://platform.openai.com/docs/models">OpenAI's list of models</a>. We're using gpt-3.5-turbo-16k because we potentially need a big context window. </li>  
      <li><b>Temperature:</b> <code>0.7</code>. Temperature runs from 0 to 1 and specifies how "random" the answer should be. For our first two templates, I set this to 0, but here I'm using 0.7 because I'm happy to have the text less determined..</li>  
      <li><b>Max Tokens:</b> <code>250</code>. This number specifies how long the reply can be. Tokens are chunks of text the model uses to do its thing. They don't quite match up with words but are close. 1 token is something like 3/4 of a word. Smaller token limits run faster.</li>  
      <li><b>JSON:</b> <code>No</code>. This asks the model to output its answer in something called JSON. We don't need to worry about that here, hence the selection of "No."</li>  
      <li><b>Output To:</b> <code>Screen + clipboard</code>. We can output the first reply from the LLM to a number of places, the screen, the clipboard, a file... Here, I've choosen the screen and clipboard so we can just paste the results into our reply.</li>  
      <li><b>Post-run Behavior:</b> <code>FULL STOP</code>. Like the choice of output, we can decide what to do after a template runs. To keep things simple, I went with "FULL STOP."</li>  
      <li><b>Hide Button:</b> <code>unchecked</code>. This determines if a button is displayed for this template in the extension's popup window. Here we left the option unchecked, but sometimes when running a chain of prompts, it can be useful to hide a button.</li>
  </ul>
  <h3><a name="working" href="posts/decline-requests/#working" class="anchor" alt="deep link to this section"></a>Working with the above template</h3>
  <p>
    To work with the above template, you could copy it and its parameters into LIT Prompts one by one, or you could download a single prompts file and upload it from the extension's <i>Templates &amp; Settings</i> screen. This will replace your existing prompts.
  </p>

  <div class="featured_img_center" style="max-width:900px;">
    <a href="images/50-days/template_upload.png"><img src="images/50-days/template_upload.png" ALT="Screenshot of the LIT Prompts Templates and Settings page showing where to upload prompts files." class="list_img_file" style="border: 1px solid #a5a5a5;"/></a>
  </div>

  <p>
    You can download a prompts file (the above template and its parameters) suitable for upload by clicking this button:
  </p>

  <div class="button_row">
    <a href="javascript:void('');" onClick="saveTextAsFile(prompts,'prompt_template.txt')" class="button" style="width:220px;">Download prompts file</a>
  </div>
  <!-- 
    =================================================
    
                    Kick the Tires

    =================================================
  --> 
  <hr>
  <h2><a name="tires" href="posts/decline-requests/#tires" class="anchor" alt="deep link to this section"></a>Kick the Tires</h2> 
  <p>
    It's one thing to read about something and another to put what you've learned into practice. Let's see how this template performs.
  </p>
  <ul>
    <li>
      <b>Inbox Zero.</b> You know what to do. I wouldn't expect your automated replies to be ready to send out of the box. Rather, If you're experience is anything like mine, you'll likely find yourself drasticly cutting from your drafts. Like a sculptor working in marble, chip away the unnecessary material to reveal the email within. 
    </li>
  </ul>
  <!-- 
    =================================================
    
                       References

    =================================================
  --> 
  <hr>
  <h2><a name="references" href="posts/decline-requests/#references" class="anchor" alt="deep link to this section"></a>TL;DR References</h2>
  <p>
    ICYMI, if you didn't click through above, you might want to give this a look now. 
  </p>
  <ul>
    <li>
      <a href="https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web" target="_blank">ChatGPT Is a Blurry JPEG of the Web</a> by Ted Chiang. Writing at the beginning of ChatGPT's rise to prominence, this article discusses the analogy between language models like ChatGPT and lossy compression algorithms. Chiang argues that while models can repackage/compress web information, they lack true understanding. Ultimately, Chiang concludes that starting with a blurry copy is not ideal when creating original content and that the struggling to express thoughts is an essential element of the writing process. 
    </li>
    <!--<li><a href="">text</a></li>-->
  </ul>
  <!-- Preview projects -->
  <div id="previews"></div>
  <script>load_previews()</script>

  
  </div>
  <!-- END PAGE CONTENT -->
  <div class="footer">
      <span class="footer_links">
        <a href="https://mastodon.social/@Colarusso" target="_blank">Mastodon</a>
        | <a href="https://github.com/colarusso" target="_blank">GitHub</a>
        | <a href="./privacy">Privacy</a> 
        | <a href="https://sadlynothavocdinosaur.com/feed.xml">RSS</a>
      </span>
      <span class="byline">Site by David Colarusso</span>
  </div>
</div>

<script>
  if (!window.location.hash) { 
    collapse_setup();
  }

  /*new GreenAudioPlayer('.gap-example');
  const audio_object = document.querySelector('.gap-example  audio');*/

  try {
		MathJax.typeset();		
	} catch (error) {}
  
  (async () => {
    prompts = await loadFile('posts/decline-requests/prompt_template.txt');
    //exported = await loadFile('posts/decline-requests/interactions.html');
  })()
</script>

<!--
Publication checklist:

- Metadata title, description, and image: X
- Updated anchor links e.g., "posts/decline-requests/": X
- Updated prompt_template.txt file in folder: X
- Metadata publication date: ? 
-->

</BODY></HTML>

