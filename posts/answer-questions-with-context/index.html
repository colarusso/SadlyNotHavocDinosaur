<!DOCTYPE html>
<HTML><HEAD>

  <!-- Set base for this page equal to domain root -->
  <base href="../../">

  <!-- Page-specific metadata -->
  <title>2.B, or Not 2.B? Have an AI answer multiple choice and true or false questions based on a reading assignment</title>
  <meta property="og:type" content="website"/>
  <meta property="og:publish_date" content="2024-01-18T00:00:00-0500"/>
  <meta property="og:title" content="2.B, or Not 2.B? Have an AI answer multiple choice and true or false questions based on a reading assignment"/>
  <meta property="og:description" content=" Yesterday, inspired by GPT-4 passing the bar exam, we tried getting an LLM to answer some reading questions about Hawkins v. McGee. The LLMs didn't do so hot, only getting 40-47% of the questions right. So, what was missing? Remember, way back in the first post where we said, &quot;If you want an LLM, or the man on the street, to summarize a text, have them read it first.&quot; Well, it turns out, if you want an LLM to answer questions about a text you should have them read it first. ðŸ˜œ Yesterday's template was divorced from context. For example, one of the questions was &quot;What was the court's decision regarding the defendant's requests for instructions?&quot; In isolation, there's no way of knowing what decision the question is asking about. So, today we'll be including that context by making the case text part of our prompt. For the record, using gpt-3.5-trubo-16k and the template below I was able to get 4 out of 5 on Tuesday's questions, and 8 out of 10 on Wednesday's questions. That's a solid 80%. When I switched the model to gpt-4, it scored 5/5 and 9/10 respectively. That's 93%! Just to remind you, yesterday's template scored 40% and 47%.  "/>
  <meta property="og:image" content="images/50-days/robot_bubble_sheet_03_square.png"/>
  <meta property="og:image:width" content="1024" />
  <meta property="og:image:height" content="1024" />

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-ST9X6H808L"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-ST9X6H808L');
  </script>

  <!-- Metadata for mobile -->
  <meta http-equiv="Content-type" content="text/html;charset=UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
  <meta name="apple-mobile-web-app-capable" content="no" />
  <link rel="apple-touch-icon" href="images/comic.png"/>

  <!-- JS & style -->
  <link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
  <link rel="stylesheet" type="text/css" href="css/style.css?v=2024-02-16c">
  <script src="js/functions.js?v=2024-02-16c"></script>
  <script src="js/spin.js"></script>

  <link rel="stylesheet" href="css/prism.css" data-noprefix="">
  <script type="text/javascript" src="js/prism.js"></script>

  <!--<script id="MathJax-script" async src="js/mathjax/tex-mml-chtml.js"></script>

  <link rel="stylesheet" type="text/css" href="css/green-audio-player.css">
  <script src="js/green-audio-player.js"></script>-->
  
  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="Sadly Not, Havoc Dinosaur" href="https://sadlynothavocdinosaur.com/feed.xml" />

</HEAD>
<BODY BGCOLOR="#ffffff" BACKGROUND="" MARGINWIDTH="0" MARGINHEIGHT="0">

<!-- Message Banner -->
<div id="msg_bar" style="display:none;"></div>

<!-- Title and search -->
<div class="title_bar">
  <div class="home">
    <a href="./" tabindex="1"><img src="images/home.png" class="home_btn"></a>
  </div>  
  <div class="search">
    <a href="javascript:show_search();" tabindex="3"><img src="images/search.png" class="search_btn"></a>
    <input id="query" type="text" tabindex="2"/>
  </div>
  <span id="title"><a href="./" class="title_home">Sadly Not, Havoc Dinosaur</a></span>
</div>

<div class="content">
  <!-- START PAGE CONTENT -->
  
  <div id="page">
  <!-- 
    =================================================
    
                      INTRODUCTION

    =================================================
  -->
  <h1 class="post_title_01">2.B, or Not 2.B?</h1>
  <div class="post_title_02">Have an AI answer multiple choice and true or false questions based on a reading assignment</div>
  <div class="featured_img_right">
    <!--<div class="audio_container_container" style="display:show;">
      <div class="audio_container">
        <b>Hear the author read <i>TK</i></b>
        <div class="gap-example player-accessible">
          <audio>
              <source src="mp3s/title.mp3" type="audio/mpeg">
          </audio>
        </div>
        <span class="playback">
          Speed: <a href="javascript:void('')" onClick="set_speed(0.5)" class="playback" id="pb05">0.5x</a> &bull;
                  <a href="javascript:void('')" onClick="set_speed(1)" class="playback" id="pb10" style="font-weight:900;">1x</a> &bull;
                  <a href="javascript:void('')" onClick="set_speed(1.5)" class="playback" id="pb15">1.5x</a> &bull;
                  <a href="javascript:void('')" onClick="set_speed(2)" class="playback" id="pb20">2x</a> &bull;
                  <a href="javascript:void('')" onClick="set_speed(3)" class="playback" id="pb30">3x</a>
        </span>
      </div>
    </div>-->
    <a href="images/50-days/robot_bubble_sheet_03.png"><img src="images/50-days/robot_bubble_sheet_03.png" ALT="A robot holding two pencils and filling out a bubble sheet" class="list_img_file"/></a>
    <div class="caption">
      I've Got THis, latent space "photography" by <a href="https://mastodon.social/@Colarusso" target="_blank" class="captionlnk">Colarusso</a>
    </div>
  </div>
  <p class="post_p">
    <a href="https://mastodon.social/@Colarusso" target="_blank" class="body_links"><img src="images/colarusso.jpg" class="headshot_small" alt="Headshot of the author, Colarusso." style="margin-top: 7px;"/></a>
    David Colaursso<br><span class="post_date">Co-director, Suffolk's <a href="https://suffolklitlab.org/" target="_blank" class="captionlnk">Legal Innovation &amp; Tech Lab</a></span>
  </p>
  <p><i>This is <b>the 20th</b> post in my series <a href="posts/50-days-of-lit-prompts">50 Days of LIT Prompts</i></a>.</p>
  <p>
    <a href="posts/answer-questions">Yesterday</a>, inspired by <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4389233" target="_blank">GPT-4 passing the bar exam</a>, we tried getting an LLM to answer some reading questions about <a href="https://www.courtlistener.com/opinion/3574015/hawkins-v-mcgee/?type=o&amp;q=HAWKINS%20v.%20McGEE&amp;type=o&amp;order_by=score%20desc&amp;stat_Precedential=on" target="_blank">Hawkins v. McGee</a>. The LLMs didn't do so hot, only getting 40-47% of the questions right. So, what was missing? Remember, way back in the <a href="posts/summarize-and-question">first post</a> where we said, "If you want an LLM, or the man on the street, to summarize a text, have them read it first." Well, it turns out, if you want an LLM to answer questions about a text you should have them read it first. ðŸ˜œ
  </p>
  <p>
    <a href="posts/answer-questions/#template">Yesterday's template</a> was divorced from context. For example, one of the questions was "What was the court's decision regarding the defendant's requests for instructions?" In isolation, there's no way of knowing what decision the question is asking about. So, today we'll be including that context by making the case text part of our prompt. For the record, using <code>gpt-3.5-trubo-16k</code> and the template below I was able to get 4 out of 5 on <a href="posts/create-multiple-choice-questions">Tuesday's questions</a>, and 8 out of 10 on <a href="posts/create-true-false-questions">Wednesday's questions</a>. That's a solid 80%. When I switched the model to <code>gpt-4</code>, it scored 5/5 and 9/10 respectively. That's 93%! Just to remind you, yesterday's template got 40% and 47%.
  </p>
  <p> 
    To be entierly clear, our <code>gpt-4</code> isn't quite the same GPT-4 used in the <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4389233" target="_blank">MBE paper</a>. The "GPT-4" moniker has pointed to differnt models over time. Also, I counted an answer as "correct" when it agreed with the GPT-generated answer provided in the prior posts. As <a href="posts/create-true-false-questions">I noted</a>, I wouldn't take these answers as gospel. It did, however, seem reasonable here to measure the LLMs' performance against the answers drafted by an LLM. That is, we are measuring how well the LLMs did on a test written by LLMs. Regardless, I think we've established there's something to be said for context. Knowing this, <b>let's build something!</b></p>
  
  <!-- END INTRO -->
  <p>
    We'll do our building in the LIT Prompts extension. If you aren't familiar with the LIT Prompts extension, don't worry. We'll walk you through setting things up before we start building. If you have used the LIT Prompts extension before, skip to <a href="posts/answer-questions-with-context/#template">The Prompt Pattern (Template)</a>.
  </p>
  <h3><a name="upnext" href="posts/answer-questions-with-context/#upnext" class="anchor" alt="deep link to this section"></a>Up Next</h3>
  <ul>
    <li><a href="posts/answer-questions-with-context/#setup" onClick="expand_setup();">Setup LIT Prompts</a></li>
    <ul>
      <li><a href="posts/answer-questions-with-context/#install" onClick="expand_setup();">Install the extension</a></li>
      <li><a href="posts/answer-questions-with-context/#point" onClick="expand_setup();">Point it at an API</a></li>
    </ul>
    <li><a href="posts/answer-questions-with-context/#template">The Prompt Pattern (Template)</a></li>
    <li><a href="posts/answer-questions-with-context/#tires">Kick the Tires</a></li>
    <li><a href="posts/answer-questions-with-context/#references">TL;DR References</a></li>
  </ul>
  <p>
    <b>Questions or comments?</b> I'm on Mastodon <a href="https://mastodon.social/@Colarusso" target="_blank">@Colarusso@mastodon.social</a>
  </p>
  <!-- 
    =================================================
    
                   Setup LIT Prompts

    =================================================
  --> 
  <hr>
  <h2><a name="setup" href="posts/answer-questions-with-context/#setup" onClick="expand_setup();" class="anchor" alt="deep link to this section"></a>Setup LIT Prompts </h2>
  <div id="expand_setup" style="text-align: left;display:none;font-size: small;">
    <a href="javascript:expand_setup();" style="text-decoration: none;">&#9658; Expand</a>
  </div>
  <div id="collapse_setup" style="text-align: left;font-size: small;">
    <a href="javascript:collapse_setup();" style="text-decoration: none;">&#9660; Collapse</a>
  </div>
  <div id="setup_extension">
    <div class="list_vid">
      <iframe class="embed_vid" src="https://www.youtube-nocookie.com/embed/Ql8aXGvLBGU" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe>
      <div class="caption">
        7 min intro video
      </div>
    </div>
    <p>
      <i><b>LIT Prompts</b></i> is a browser extension built at Suffolk University Law School's <a href="https://suffolklitlab.org/" target="_blank">Legal Innovation and Technology Lab</a> to help folks explore the use of <a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank">Large Language Models</a> (LLMs) and <a href="https://en.wikipedia.org/wiki/Prompt_engineering" target="_blank">prompt engineering</a>. LLMs are sentence completion machines, and prompts are the text upon which they build. Feed an LLM a prompt, and it will return a plausible-sounding follow-up (e.g., "Four score and seven..." might return "years ago our fathers brought forth..."). LIT Prompts lets users create and save prompt templates based on data from an active browser window (e.g., selected text or the whole text of a webpage) along with text from a user. Below we'll walk through a specific example. 
    </p>
    <p>
      To get started, follow <b>the first four minutes</b> of the intro video or the steps outlined below. <i>Note: The video only shows Firefox, but once you've installed the extension, the steps are the same.</i>
    </p>
    <h3><a name="install" href="posts/answer-questions-with-context/#install" class="anchor" alt="deep link to this section"></a>Install the extension</h3>
    <p>Follow the links for your browser.</p>
    <ul>
      <li>
        <b>Firefox:</b> (1) visit the extension's <a href="https://addons.mozilla.org/en-US/firefox/addon/lit-prompts/" target="_blank">add-ons page</a>; (2) click "Add to Firefox;" and (3) grant permissions.
      </li>
      <li>
        <b>Chrome:</b>  (1) visit the extension's <a href="https://chromewebstore.google.com/detail/lit-prompts/hfeojjmldhebkeknfapoghcohkhffcmp" target="_blank">web store page</a>; (2) click "Add to Chrome;" and (3) review permissions / "Add extension."
      </li>
    </ul>
    <p>
      If you don't have Firefox, you can <a href="https://www.mozilla.org/en-US/firefox/new/" target="_blank">download it here</a>. Would you rather use Chrome? <a href="https://www.google.com/chrome/" target="_blank">Download it here</a>.
    </p>
    <h3><a name="point" href="posts/answer-questions-with-context/#point" class="anchor" alt="deep link to this section"></a>Point it at an API</h3>
    <p>
      Here we'll walk through how to use an LLM provided by OpenAI, but you don't have to use their offering. If you're interested in alternatives, you can find them <a href="https://github.com/SuffolkLITLab/prompts/tree/main#openai-compatible-api-integration" target="_blank">here</a>. You can even run your LLM locally, avoiding the need to share your prompts with a third-party. If you need an OpenAI account, you can <a href="https://platform.openai.com/signup" target="_blank">create one here</a>. Note: when you create a new OpenAI account you are given a limited amount of free API credits. If you created an account some time ago, however, these may have expired. If your credits have expired, you will need to enter a <a href="https://platform.openai.com/account/billing/overview" target="_blank">billing method</a> before you can use the API. You can check the state of any credits <a href="https://platform.openai.com/usage" target="_blank">here</a>. 
    </p>
    <p>
      Login to <a href="https://openai.com/" target="_blank">OpenAI</a>, and navigate to the <a href="https://platform.openai.com/docs/" target="_blank">API documentation</a>. 
    </p>
    <div class="featured_img_center">
      <a href="images/50-days/OpenAI_keys.png"><img src="images/50-days/OpenAI_keys.png" ALT="Screenshot of the OpenAI API Keys page showing where to click to create a new key." class="list_img_file" style="border: 1px solid #a5a5a5;"/></a>
    </div>
    <p>Once you are looking at the API docs, follow the steps outlined in the image above. That is:
    <ol>
      <li>Select "API keys" from the left menu</li>
      <li>Click "+ Create new secret key"</li>
    </ol>
    <hr>
    <p>
      On LIT Prompt's <i>Templates & Settings</i> screen, set your API Base to <code>https://api.openai.com/v1/chat/completions</code> and your API Key equal to the value you got above after clicking "+ Create new secret key".  You get there by clicking the <i>Templates & Settings</i> button in the extension's popup:
    </p>
    <ol>
      <li>open the extension</li>
      <li>click on  <i>Templates & Settings</i></li>
      <li>enter the API Base and Key (under the section <i>OpenAI-Compatible API Integration</i>)</li>
    </ol>
    <div class="featured_img_center">
      <a href="images/50-days/popup.png"><img src="images/50-days/popup.png" ALT="Screenshot of the LIT Prompts extension popup." class="list_img_file" style="border: 1px solid #a5a5a5;"/></a>
    </div>
    <p>
      Once those two bits of information (the API Base and Key) are in place, you're good to go. Now you can edit, create, and run prompt templates. Just open the LIT Prompts extension, and click one of the options. I suggest, however, that you read through the <i>Templates and Settings</i> screen to get oriented. You might even try out a few of the preloaded prompt templates. This will let you jump right in and get your hands dirty in the next section. 
    </p>
    <div class="featured_img_center">
      <a href="images/50-days/credentials.png"><img src="images/50-days/credentials.png" ALT="Screenshot of the LIT Prompts extension popup." class="list_img_file" style="border: 1px solid #a5a5a5;"/></a>
    </div>
    <p>
      <span style="background:yellow;">If you receive an error when trying to run a template after entering your Base and Key, and you are using OpenAI, make sure to check the state of any credits <a href="https://platform.openai.com/usage" target="_blank">here</a>. If you don't have any credits, you will need a billing method on file.</span>
    </p>
    <p>
      <i>If you found this hard to follow, consider following along with the first four minutes of the video <a href="posts/answer-questions-with-context/#setup">above</a>. It covers the same content. It focuses on Firefox, but once you've installed the extension, the steps are the same.</i>
    </p>
  </div>
  <!-- 
    =================================================
    
                   Write Your Template

    =================================================
  --> 
  <hr>
  <h2><a name="template" href="posts/answer-questions-with-context/#template" class="anchor" alt="deep link to this section"></a>The Prompt Pattern (Template)</h2>

  <div class="featured_img_right">
    <a href="images/boxquote.png"><img src="images/boxquote.png" ALT="A slide showing the Georeg Box quote: All models are wrong, but some models are useful." class="list_img_file"/></a>
    <div class="caption">
      Maps are models; they don't show everything. That's okay as long as you don't confuse the map for the territory.
    </div>
  </div>

  <p>
    When crafting a LIT Prompts template, we use a mix of plain language and variable placeholders. Specifically, you can use double curly brackets to encase predefined variables. If the text between the brackets matches one of our predefined variable names, that section of text will be replaced with the variable's value. Today we'll be using two of our favorites, <code>{{highlighted}}</code> and <code>{{scratch}}</code>. See the extension's <a href="https://github.com/SuffolkLITLab/prompts#prompt-templates" target="_blank">documentation</a>. 
  </p>
  <p>
    The <code>{{highlighted}}</code> variable contains any text you have highlighted/selected in the active browser tab when you open the extension. The <code>{{scratch}}</code> variable contains the text in your Scratch Pad. Remember, the scratch pad is accessible from the extension's popup window. The button is to the right of the Settings & Templates button that you have used before. 
  </p>
  <p> 
    To run the template, make sure that the text of the reading is in your Scratch Page, highlight the text of your question, not including the answer, and trigger the extension. If all goes well the LLM will "read" the text along with your question and return an answer.
  </p>
  </p>
  <p>Here's the template's title.</p>
  <p><code>Answer the selected question</code></p>
  <p>Here's the template's text.</p>
  <!-- 
    #########################
    #########################
    #####   start code   ####
    #########################
    #########################
  -->
  <section class="line-numbers">
    <pre class="language-xxx" style="white-space:pre-wrap;"><code>I'm going to show you the text of a reading assignment followed by a "multiple choice" or "true or false" question for that reading. Then I'm going to ask you to correctly answer the question.

READING:

{{scratch}}

QUESTION: 

{{highlighted}}

Now, provide the correct answer:       
      
</code></pre>
  </section>
  <!-- 
    #########################
    #########################
    #####    end code    ####
    #########################
    #########################
  -->
  <p>And here are the template's parameters:</p>
  <ul>

    <li><b>Output Type:</b> <code>LLM</code>. This choice means that we'll "run" the template through an LLM (i.e., this will ping an LLM and return a result). Alternatively, we could have chosen "Prompt," in which case the extension would return the text of the completed template. </li>
    
    <li><b>Model:</b> <code>gpt-3.5-turbo-16k</code>. This input specifies what model we should use when running the prompt. Available models differ based on your API provider. See e.g., <a href="https://platform.openai.com/docs/models" target="_blank">OpenAI's list of models</a>. Note: <code>gpt-4</code> did pretty well in the tests I described above, but it's wicked expensive.</li>  
    
    <li><b>Temperature:</b> <code>0</code>. Temperature runs from 0 to 1 and specifies how "random" the answer should be. Since we're seeking fidelity to a text, I went with the least "creative" settingâ€”0.</li>  
                
    <li><b>Max Tokens:</b> <code>500</code>. This number specifies how long the reply can be. Tokens are chunks of text the model uses to do its thing. They don't quite match up with words but are close. 1 token is something like 3/4 of a word. Smaller token limits run faster.</li>  
    
    <li><b>JSON:</b> <code>No</code>. This asks the model to output its answer in something called JSON. We don't need to worry about that here, hence the selection of "No."</li>  
    
    <li><b>Output To:</b> <code>Screen Only</code>. We can output the first reply from the LLM to a number of places, the screen, the clipboard, a file... Here, we're content just to have it go to the screen.</li>  
          
    <li><b>Post-run Behavior:</b> <code>FULL STOP</code>. Like the choice of output, we can decide what to do after a template runs. To keep things simple, I went with "FULL STOP."</li>  
   
    <li><b>Hide Button:</b> <code>unchecked</code>. This determines if a button is displayed for this template in the extension's popup window. </li>    

  </ul>

  <h3><a name="working" href="posts/answer-questions-with-context/#working" class="anchor" alt="deep link to this section"></a>Working with the above templates</h3>
  <p>
    To work with the above template, you could copy it and its parameters into LIT Prompts one by one, or you could download a single prompts file and upload it from the extension's <i>Templates &amp; Settings</i> screen. This will replace your existing prompts.
  </p>

  <div class="featured_img_center" style="max-width:900px;">
    <a href="images/50-days/template_upload.png"><img src="images/50-days/template_upload.png" ALT="Screenshot of the LIT Prompts Templates and Settings page showing where to upload prompts files." class="list_img_file" style="border: 1px solid #a5a5a5;"/></a>
  </div>
  <p>
    You can download a prompts file (the above template and its parameters) suitable for upload by clicking this button:
  </p>

  <div class="button_row">
    <a href="javascript:void('');" onClick="saveTextAsFile(prompts,'prompt_template.txt')" class="button" style="width:220px;">Download prompts file</a>
  </div>
  <!-- 
    =================================================
    
                    Kick the Tires

    =================================================
  --> 
  <hr>
  <h2><a name="tires" href="posts/answer-questions-with-context/#tires" class="anchor" alt="deep link to this section"></a>Kick the Tires</h2> 
  <p>
    It's one thing to read about something and another to put what you've learned into practice. Let's see how this template performs. 
  </p>
  <ul>
    <li>
      <b>Testing the tester</b>. Find a reading and some questions (remember, you can make your own), and see how the template does. Swap in a more or less powerful model.
    </li>
</ul>
  <!-- 
    =================================================
    
                       References

    =================================================
  --> 
  <hr>
  <h2><a name="references" href="posts/answer-questions-with-context/#references" class="anchor" alt="deep link to this section"></a>TL;DR References</h2>
  <p>
    ICYMI, here are blubs for a selection of works I linked to in this post. If you didn't click through above, you might want to give them a look now. 
    <!-- ICYMI, if you didn't click through above, you might want to give this a look now. -->
  </p>

  <div class="list_img">
    <a href="images/50-days/gpt_mbe.png"><img src="images/50-days/gpt_mbe.png" ALT="Figure 1 from GPT-4 Passes the Bar Exam showing the performance over various LLMs on the multi-state bar exam." class="list_img_file"/></a>
    <div class="caption">
      Figure 1 from <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4389233" target="_blank" class="captionlnk">GPT-4 Passes the Bar Exam</a> showing the performance over various LLMs on the multi-state bar exam. <a href="images/50-days/gpt_mbe.png" class="captionlnk">Click to enlarge</a>.
    </div>
  </div>

  <ul>

    <li>
      <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4389233" target="_blank">GPT-4 Passes the Bar Exam</a> by Daniel Martin Katz, Michael James Bommarito, Shang Gao, and Pablo Arredondo. When this paper came out it caused quite a stir in legal academia. As the title suggests, it demonstrated that an LLM could pass the Multi State Bar Exam. Don't confuse this with the arrival of AI lawyers. What's undeniable is that such an accomplishment says something interesting. I tend to think it says more about the way we test lawyers than most commentary on it would suggest, but it's the source of something you may have heard somewhere else, "AI Passes the Bar!!!"
    </li>

    <li>
      <a href="https://www.gutenberg.org/ebooks/1524" target="_blank">Hamlet, Prince of Denmark</a> by William Shakespeare. Technically, I didn't link to this above, but I did allude to it. Either way, I'll take any chance I can to share the fact that Project Gutenberg has a great selection of public domain works available to read on the web or with your e-reader. The above link will get you the whole play. 
    </li>

    <!--<li><a href="">text</a></li>-->
  </ul>
  
  <!-- 
  =================================================
  
                  Preview projects

  =================================================
  --> 
  <div id="previews"></div>
  
  </div>
  <!-- END PAGE CONTENT -->
  <div class="footer">
      <span class="footer_links">
        <a href="https://mastodon.social/@Colarusso" target="_blank">Mastodon</a>
        | <a href="https://github.com/colarusso" target="_blank">GitHub</a>
        | <a href="./privacy">Privacy</a> 
        | <a href="https://sadlynothavocdinosaur.com/feed.xml">RSS</a>
      </span>
      <span class="byline">Site by David Colarusso</span>
  </div>
</div>

<script>

  /*new GreenAudioPlayer('.gap-example');
  const audio_object = document.querySelector('.gap-example  audio');

  try {
		MathJax.typeset();		
	} catch (error) {}*/
  
  (async () => {
    prompts = await loadFile('posts/answer-questions-with-context/prompt_template.txt');
    //exported = await loadFile('posts/answer-questions-with-context/interactions.html');
  })()
</script>

</BODY></HTML>

