<!DOCTYPE html>
<HTML><HEAD>

  <!-- Set base for this page equal to domain root -->
  <base href="../../">

  <!-- Page-specific metadata -->
  <title>TL;DR References (A.I. &amp; Large Language Models): A reading list for folks interested in understanding large language models (LLMs)</title>
  <meta property="og:type" content="website"/>
  <meta property="og:publish_date" content="2024-01-18T00:00:00-0500"/>
  <meta property="og:title" content="TL;DR References (A.I. &amp; Large Language Models): A reading list for folks interested in understanding large language models (LLMs)"/>
  <meta property="og:description" content="ICYMI, here are blubs for a selection of works referenced as part of my 50 Days of LIT Prompts series. Most of them are about AI, but I have slipped in some random Shakespeare. üòâ If you're looking for context, there are links back to the posts from which they came. The serise is still unfolding. So, expect this list to grow. Updated regularly. "/>
  <meta property="og:image" content="images/50-days/reading_room_square.png"/>
  <meta property="og:image:width" content="1024" />
  <meta property="og:image:height" content="1024" />

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-ST9X6H808L"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-ST9X6H808L');
  </script>

  <!-- Metadata for mobile -->
  <meta http-equiv="Content-type" content="text/html;charset=UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
  <meta name="apple-mobile-web-app-capable" content="no" />
  <link rel="apple-touch-icon" href="images/comic.png"/>

  <!-- JS & style -->
  <link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
  <link rel="stylesheet" type="text/css" href="css/style.css?v=2024-02-16c">
  <script src="js/functions.js?v=2024-02-16c"></script>
  <script src="js/spin.js"></script>

  <link rel="stylesheet" href="css/prism.css" data-noprefix="">
  <script type="text/javascript" src="js/prism.js"></script>

  <!--<script id="MathJax-script" async src="js/mathjax/tex-mml-chtml.js"></script>

  <link rel="stylesheet" type="text/css" href="css/green-audio-player.css">
  <script src="js/green-audio-player.js"></script>-->
  
  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="Sadly Not, Havoc Dinosaur" href="https://sadlynothavocdinosaur.com/feed.xml" />

</HEAD>
<BODY BGCOLOR="#ffffff" BACKGROUND="" MARGINWIDTH="0" MARGINHEIGHT="0">

<!-- Message Banner -->
<div id="msg_bar" style="display:none;"></div>

<!-- Title and search -->
<div class="title_bar">
  <div class="home">
    <a href="./" tabindex="1"><img src="images/home.png" class="home_btn"></a>
  </div>  
  <div class="search">
    <a href="javascript:show_search();" tabindex="3"><img src="images/search.png" class="search_btn"></a>
    <input id="query" type="text" tabindex="2"/>
  </div>
  <span id="title"><a href="./" class="title_home">Sadly Not, Havoc Dinosaur</a></span>
</div>

<div class="content">
  <!-- START PAGE CONTENT -->
  
  <div id="page">
  <!-- 
    =================================================
    
                      INTRODUCTION

    =================================================
  -->
  <h1 class="post_title_01">TL;DR References (A.I. &amp; Large Language Models)</h1>
  <div class="post_title_02">A reading list for folks interested in understanding <a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" style="color:#555">large language models</a> (LLMs)</div>
  <div class="featured_img_right">
    <!--<div class="audio_container_container" style="display:show;">
      <div class="audio_container">
        <b>Hear the author read <i>TK</i></b>
        <div class="gap-example player-accessible">
          <audio>
              <source src="mp3s/title.mp3" type="audio/mpeg">
          </audio>
        </div>
        <span class="playback">
          Speed: <a href="javascript:void('')" onClick="set_speed(0.5)" class="playback" id="pb05">0.5x</a> &bull;
                  <a href="javascript:void('')" onClick="set_speed(1)" class="playback" id="pb10" style="font-weight:900;">1x</a> &bull;
                  <a href="javascript:void('')" onClick="set_speed(1.5)" class="playback" id="pb15">1.5x</a> &bull;
                  <a href="javascript:void('')" onClick="set_speed(2)" class="playback" id="pb20">2x</a> &bull;
                  <a href="javascript:void('')" onClick="set_speed(3)" class="playback" id="pb30">3x</a>
        </span>
      </div>
    </div>-->
    <a href="images/50-days/reading_room.png"><img src="images/50-days/reading_room.png" ALT="AI-Generated image of the New York Public Library Reading Room" class="list_img_file"/></a>
    <div class="caption">
      Reading Room, latent space "photography" by <a href="https://mastodon.social/@Colarusso" target="_blank" class="captionlnk">Colarusso</a>
    </div>
  </div>
  <p class="post_p">
    <a href="https://mastodon.social/@Colarusso" target="_blank" class="body_links"><img src="images/colarusso.jpg" class="headshot_small" alt="Headshot of the author, Colarusso." style="margin-top: 7px;"/></a>
    David Colaursso<br><span class="post_date">Co-director, Suffolk's <a href="https://suffolklitlab.org/" target="_blank" class="captionlnk">Legal Innovation &amp; Tech Lab</a></span>
  </p>
  <p>
    ICYMI, here are blubs for a selection of works referenced as part of my <a href="posts/50-days-of-lit-prompts">50 Days of LIT Prompts</a> series. Most of them are about LLMs and AI, but I have slipped in some random Shakespeare. üòâ If you want to understand the context in which I referenced them, there are links to the posts from which they came. I've aimed, however, to order them here such that they would made sense as readings absent that context. That being said, the serise is still unfolding. So, expect this list to grow. <i style="background-color: bisque;">Updated regularly.</i></a>
  </p>
  <p><b>Key:</b> üóûÔ∏è Popular Press/General Audaince | ‚öñÔ∏è Law Journalish | üìñ Bookish | ü§ñ Technical or Social Sci Paperish | üåé Blog Post | üé≠ Play or Movie. Things don't always fit in nice buckets, hence the use of "ish."
  </p>
  <ol>

    <li>
      <a href="https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web" target="_blank">ChatGPT Is a Blurry JPEG of the Web</a> by Ted Chiang. Writing at the beginning of ChatGPT's rise to prominence, this article discusses the analogy between language models like ChatGPT and lossy compression algorithms. Chiang argues that while models can repackage/compress web information, they lack true understanding. Ultimately, Chiang concludes that starting with a blurry copy is not ideal when creating original content and that the struggling to express thoughts is an essential element of the writing process. 
    </br>üóûÔ∏è | Referenced in: <a href="">XXXX</a>
    </li></br>

    <li>
      <a href="https://unlocked.microsoft.com/ai-anthology/ada-palmer/" target="_blank">We are an information revolution species</a> by Ada Palmer.  
      Palmer discusses the ongoing information revolution and the impact of AI on society. She emphasizes that information revolutions have been a normal part of human life for centuries, and AI is just the latest iteration of this trend. Palmer argues that AI has the potential to democratize the power to create media, such as video games and movies, and enable more people to express themselves artistically. She acknowledges that AI may threaten certain livelihoods, but believes that thoughtful transitions and safety nets can help mitigate these challenges. Palmer also addresses concerns about fake news and propaganda, noting that society has always learned to combat the dangers of new media. She concludes by emphasizing the importance of policy and planning to ensure that the rollout of AI is beneficial for all.
      <i>Summary based on a draft from our <a href="posts/summarize-and-question">day one template</a>.</i>
    </br>üóûÔ∏è üåé | Referenced in: <a href="">XXXX</a>
    </li></br>

    <li><a href="https://www.newyorker.com/science/annals-of-artificial-intelligence/will-ai-become-the-new-mckinsey" target="_blank">Will A.I. Become the New McKinsey?</a> by Ted Chiang.
      This article explores the potential risks and consequences of artificial intelligence (A.I.) in relation to capitalism. Chiang suggests that A.I. can be seen as a management-consulting firm, similar to McKinsey & Company, which concentrates wealth and disempowers workers. He argues that A.I. currently assists capital at the expense of labor, and questions whether there is a way for A.I. to assist workers instead of management. Chiang also discusses the need for economic policies to distribute the benefits of technology appropriately, as well as the importance of critical self-examination by those building world-shaking technologies. He concludes by emphasizing the need to question the assumption that more technology is always better and to engage in the hard work of building a better world. <i>Summary based on a draft from our <a href="posts/summarize-and-question">day one template</a>.</i>
    </br>üóûÔ∏è | Referenced in: <a href="">XXXX</a>
    </li></br>
        
    <li>
      <a href="https://www.predictionmachines.ai/" target="_blank">Prediction Machines - The Simple Economics of Artificial Intelligence</a> by Professors Ajay Agrawal, Joshua Gans, and Avi Goldfarb. I find the framing of AI tools as "prediction machines" to be both accurate and concise. The first edition of this book was a very good framing of AI as prediction. Apparently, there is a new edition of the book though I've only read the original. That version was written well before the current shift in the meaning of "AI." When the first edition was published, the vernacular use of AI was most often attached to <i>machine learning</i>; now it attaches to LLMs. 
    </br>üóûÔ∏è üìñ | Referenced in: <a href="">XXXX</a>
    </li></br>
    
    <li>
      <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4389233" target="_blank">GPT-4 Passes the Bar Exam</a> by Daniel Martin Katz, Michael James Bommarito, Shang Gao, and Pablo Arredondo. When this paper came out it caused quite a stir in legal academia. As the title suggests, it demonstrated that an LLM could pass the Multi State Bar Exam. Don't confuse this with the arrival of AI lawyers. What's undeniable is that such an accomplishment says something interesting. I tend to think it says more about the way we test lawyers than most commentary on it would suggest, but like the next link, it's the source of something you may have heard somewhere else, "AI Passes the Bar!!!" ‚öñÔ∏è
    </br>‚öñÔ∏è ü§ñ | Referenced in: <a href="">XXXX</a>
    </li></br>
    
    <li>
      <a href="https://simonwillison.net/2023/Nov/27/prompt-injection-explained/" target="_blank">Prompt injection explained, November 2023 edition</a> by the person who coined the term‚ÄîSimon Willison. TL;DR: Prompt injection is a security vulnerability where users can override intended instructions in a language model, by "hiding" instructions in texts, potentially causing harm or unauthorized access, and we don't have a 100% solution to this. So, there a lot of things folks want to build with these tools that the shouldn't. 
    </br>üåé | Referenced in: <a href="">XXXX</a>
    </li></br>

    <li>
      <a href="https://dl.acm.org/doi/10.1145/3442188.3445922" target="_blank">On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ü¶ú</a> by Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. There's a lot of history behind this paper. It was part of <a href="https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/" target="_blank">a chain of events</a> that forced Timnit Gebru to leave Google where she was the co-lead of their ethical AI team, but more than that, it's one of the foundational papers in AI ethics, not to be confused with the field of "AI safety," which we will discuss later. It discusses several risks associated with large language models, including environmental/financial costs, biased language, lack of cultural nuance, misdirection of research, and potential for misinformation. If you want to engage critically with LLMs, this paper is a must read.
    </br>ü§ñ | Referenced in: <a href="">XXXX</a>
    </li></br>


    <li>
      <a href="https://muse.jhu.edu/pub/3/article/916425" target="_blank">Any sufficiently transparent magic . . .</a> by Damien Patrick Williams.     
      The article explores the connections between religious perspectives, myth, and magic with the development of algorithms and artificial intelligence (AI). The author argues that these elements are not only lenses to understand AI but are also foundational to its development. The article highlights the need to consider social and experiential knowledge in AI research and emphasizes the importance of engaging with marginalized voices to better understand and mitigate the harms of AI. The author also draws parallels between AI and magical beings, such as djinn, suggesting that AI systems may fulfill desires as thoroughly as they would for themselves. The article critiques the terminology and hype surrounding AI, calling for a more intentional examination of the religious and magical aspects of AI. <i>Summary based on a draft from our <a href="posts/summarize-and-question">day one template</a>.</i> ü§ñ 
    </br>| Referenced in: <a href="">XXXX</a>
    </li></br>

    <li>
      <a href="https://arxiv.org/abs/1301.3781" target="_blank">Efficient Estimation of Word Representations in Vector Space</a> by Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. This is the paper that introduced word2vec to the world. It's a technical paper. If that scares you, consider looping back and looking at it after we finish this week's micro-lessons. It might make more sense given that perspective as we'll spend the next several posts unpacking what word2vec does and why it matters.
    </br>| Referenced in: <a href="">XXXX</a>
    </li></br>

        
    <li><a href="https://goatgreatesteconomistofalltime.ai/en" target="_blank">GOAT:
      Who is the Greatest Economist of all Time and Why Does it Matter?</a> A generative book by Tyler Cowen. From the site, 

      "Do you yearn for something more than a book? And yet still love books? How about a book you can query, and it will answer away to your heart's content? How about a book that will create its own content, on demand, or allow you to rewrite it? A book that will tell you why it is (sometimes) wrong?
      
      That is what I have tried to build with my latest work. It's called GOAT: Who is the Greatest Economist of all Time and Why Does it Matter?"
    </br>| Referenced in: <a href="">XXXX</a>
    </li></br>

    <li>
      <a href="https://www.gutenberg.org/ebooks/1513" target="_blank">Romeo and Juliet</a> by William Shakespeare. Technically, I didn't link to this above, but I did allude to it a couple of times. Either way, I'll take any chance I can to share the fact that Project Gutenberg has a great selection of public domain works available to read on the web or with your e-reader. The above link will get you the whole play. 
    </br>| Referenced in: <a href="">XXXX</a>
    </li></br>

    <li>
      <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1753333" target="_blank">The Dictionary Is Not a Fortress: Definitional Fallacies and a Corpus-Based Approach to Plain Meaning</a> 
      by Stephen C. Mouritsen. This paper discusses the limitations of relying solely on dictionaries for determining the meaning of statutory terms in legal interpretation. The author argues that dictionaries are not infallible and can be subject to definitional fallacies. Instead, the author proposes a corpus-based approach to determining the ordinary meaning of statutory terms, concluding that Corpus Linguistics has the potential to provide a more objective and empirical approach to statutory interpretation. As you might imagine the devil is in the details, and though many have taken up the charge of legal corpus linguistics others have questioned its application, hence, my next reference.
    </br>| Referenced in: <a href="">XXXX</a>
    </li></br>

    <li>
      <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3567408" target="_blank">Legal Corpus Linguistics and the Half-Empirical Attitude</a> by Anya Bernstein. Its proponents argue that corpus linguistics provides empirical grounding to claims about ordinary language. However, the paper argues that legal corpus linguistics falls short in delivering on this promise because it ignores the relevant legal and institutional contexts in which legal language is produced and interpreted. The author refers to this approach as a "half-empirical attitude" because it treats normative claims as empirical findings. The paper suggests that legal corpus linguistics could be useful to legal theory if it embraces a more comprehensive empirical attitude.
    </br>| Referenced in: <a href="">XXXX</a>
    </li></br>

    <li>
      <a href="https://dl.acm.org/doi/10.1145/3442188.3445922" target="_blank">On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ü¶ú</a> by Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. There's a lot of history behind this paper. It was part of <a href="https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/" target="_blank">a chain of events</a> that forced Timnit Gebru to leave Google where she was the co-lead of their ethical AI team, but more than that, it's one of the foundational papers in AI ethics, not to be confused with the field of "AI safety," which we will discuss later. It discusses several risks associated with large language models, including environmental/financial costs, biased language, lack of cultural nuance, misdirection of research, and potential for misinformation. If you want to engage critically with LLMs, this paper is a must read.
    </br>| Referenced in: <a href="">XXXX</a>
    </li></br>

    <li>
      <a href="https://www.techdirt.com/2024/01/05/copyright-liability-on-llms-should-mostly-fall-on-the-prompter-not-the-service/" target="_blank">Wherein The Copia Institute Tells The Copyright Office There's No Place For Copyright Law In AI Training </a> by  Cathy Gellis. 
      This article outlines a comment filed by the Copia Institute with the US Copyright Office, arguing that copyright law should not apply to AI training. The comment states that copyright law should not interfere with AI training because it would impede the public's right to consume works. They argue that AI training is an extension of the public's right to use tools, including software tools, to help them consume works. The comment also notes that AI training is not the same as copying or distributing copyrighted works, as it involves the analysis and processing of information rather than the creation of new works. They conclude that copyright law should not have a role in AI training and that AI training should be considered fair use or exempt from copyright altogether. 
    </br>| Referenced in: <a href="">XXXX</a>
    </li></br>

    <li>
      <a href="https://www.techdirt.com/2023/11/03/wherein-the-copia-institute-tells-the-copyright-office-theres-no-place-for-copyright-law-in-ai-training/" target="_blank">Copyright Liability On LLMs Should Mostly Fall On The Prompter, Not The Service </a> by  Ira Rothken. 
      The use of large language models (LLMs) like ChatGPT has raised questions about the bounds of fair use and the responsibilities of AI developers and users in relation to copyright law. In this article Rothken proposes the "Training and Output" (TAO) Doctrine as a way to address these issues. The TAO Doctrine suggests that if an AI LLM engine is trained using copyrighted works and the outputs generated are based on user prompts, the responsibility for any potential copyright infringement should lie with the user, not the AI system. This approach recognizes the dual-use nature of AI technologies and emphasizes the importance of user intent and inputs in determining the nature of the output and any downstream usage. The TAO Doctrine aims to strike a balance between fostering innovation and respecting copyright laws. 
    </br>| Referenced in: <a href="">XXXX</a>
    </li></br>

    <li>
      <a href="https://arxiv.org/abs/1310.4546" target="_blank">Distributed Representations of Words and Phrases and their Compositionality</a> by 
      Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. This is the second word2vec paper, and it is here you can find a discussion of the country-capital directionality we noted above.
    </br>| Referenced in: <a href="">XXXX</a>
    </li></br>

    <li><a href="https://shapeofdata.wordpress.com/2013/04/16/visualization-and-projection/" target="_blank">Visualization and Projection</a> by Jesse Johnson. 
      The article discusses the concept of visualization and projection in the context of analyzing high dimensional data sets. The author explains that while it is important to analyze data without being able to see it, visualization can still be useful in certain cases. The goal of visualization is to represent the data points in a lower dimensional space so that patterns can be recognized by the human brain. The article explains that projection is the process of representing high dimensional data in a lower dimensional space, similar to making shadow puppets. The author discusses linear projection and how it can be used to ignore certain dimensions of the data. The article also introduces the concept of principal component analysis (PCA) and how it can be used to find the directions in which the data is most spread out, allowing for a relatively good picture of the data. However, the article notes that PCA may not preserve the structure of data sets with curved or more complicated distributions. <i>Summary based on a draft from our <a href="posts/summarize-and-question">day one template</a>.</i>
    </br>| Referenced in: <a href="">XXXX</a>
    </li></br>

    <li><a href="https://cloud.google.com/blog/products/ai-machine-learning/problem-solving-with-ml-automatic-document-classification" target="_blank">Problem-solving with ML: automatic document classification</a> by Ahmed Kachkach. 
      This blog post discusses how machine learning can be used to automatically label news articles. The author uses a public dataset from the BBC, which contains articles labeled under different categories such as business, entertainment, politics, sport, and tech. The post explains how data can be extracted and pre-processed, and how machine learning models can be built and evaluated. The author benchmarks three models - <a href="posts/define-words/#logistic">Logistic Regression</a>, Naive Bayes, and Random Forest - and evaluates their performance using cross-validation. The results show that both Logistic Regression and Naive Bayes perform extremely well, with Logistic Regression having a slight advantage. The post also discusses model interpretation and how to analyze misclassified examples. Overall, the post demonstrates how off-the-shelf machine learning tools can be used to solve complex tasks like document classification. <i>Summary based on a draft from our <a href="posts/summarize-and-question">day one template</a>.</i>
    </br>| Referenced in: <a href="">XXXX</a>
    </li></br>



    
    <li>
      <a href="https://www.nonprofittechy.com/2024/01/30/some-quick-thoughts-about-integrating-ai-with-law-school-clinical-practice/" target="_blank">Some quick thoughts about integrating AI with law school clinical practice</a> by Quinten Steenhuis.  
      I co-direct the LIT Lab with Quinten and really apprechiate his take on the use of AI in law school clinics. He believes that law school clinics should be using generative AI tools, but acknowledges that it requires careful thought and planning. Steenhuis suggests several safe uses for AI in clinical education, such as solving the blank page problem, brainstorming, extracting information, classifying, editing, translating, and simplifying. He also addresses concerns about teaching generative AI, including the risk of automation bias and perpetuating biases. Steenhuis emphasizes the importance of teaching students how to critically evaluate AI output and suggests integrating AI lessons into existing curriculum. He concludes by stating that generative AI has practical uses and ignoring it in clinical practice will put law students at a disadvantage.
      <i>Summary based on a draft from our <a href="posts/summarize-and-question">day one template</a>.</i>
    </br>| Referenced in: <a href="">XXXX</a>
    </li></br>

    <li>
      <a href="https://en.wikipedia.org/wiki/The_Paper_Chase_(film)" target="_blank">The Paper Chase (1973 Film)</a> Directed by 	James Bridges.  
      "The Paper Chase" is a 1973 American comedy-drama. It is based on John Jay Osborn Jr.'s 1971 novel of the same name. The film follows James Hart, a first-year law student at Harvard Law School, as he navigates his studies and his complicated relationship with Professor Charles Kingsfield, a demanding contract law instructor. John Houseman won an Academy Award for his performance as Professor Kingsfield. The film received positive reviews for its portrayal of the intense and competitive environment of law school. It was followed by a television series that ran for four seasons, continuing the story of James Hart's law school journey. 
      <i>Summary based on a draft from our <a href="posts/summarize-and-question">day one template</a>.</i>
    </br>| Referenced in: <a href="">XXXX</a>
    </li></br>

    <li>
      <a href="https://law.mit.edu/pub/unsupervised-machine-scoring-of-free-response-answers/release/1" target="_blank">Unsupervised Machine Scoring of Free Response Answers‚ÄîValidated Against Law School Final Exams</a> by David Colarusso. 
      This paper presents a novel method for unsupervised machine scoring of short answer and essay question responses, relying solely on a sufficiently large set of responses to a common prompt, absent the need for pre-labeled sample answers‚Äîgiven said prompt is of a particular character. That is, for questions where ‚Äúgood‚Äù answers look similar, ‚Äúwrong‚Äù answers are likely to be ‚Äúwrong‚Äù in different ways. Consequently, when a collection of text embeddings for responses to a common prompt are placed in an appropriate feature space, the centroid of their placements can stand in for a model answer, providing a lodestar against which to measure individual responses. This paper examines the efficacy of this method and discusses potential applications. 
    </br>| Referenced in: <a href="">XXXX</a>
    </li></br>


    <li>
      <a href="https://www.gutenberg.org/ebooks/1524" target="_blank">Hamlet, Prince of Denmark</a> by William Shakespeare. Technically, I didn't link to this above, but I did allude to it a couple of times. Either way, I'll take any chance I can to share the fact that Project Gutenberg has a great selection of public domain works available to read on the web or with your e-reader. The above link will get you the whole play. 
    </br>| Referenced in: 
    <ul>
      <li><a href="posts/answer-questions">A Hawk from a Handsaw: Have an AI "guess" the right answers for multiple choice and true or false questions</a></li>
      <li><a href="posts/answer-questions-with-context">2.B, or Not 2.B? Have an AI answer multiple choice and true or false questions based on a reading assignment</a></li>
    </ul>
    </li></br>


    <li>
      <a href="https://colarusso.github.io/dm/" target="_blank">Dungeon Master's Helper</a> by David Colarusso. 
      This webapp is meant as a handy tool for game masters (Dungeon Masters in the D&D world). It has tools to help folks run ability checks and the like, and importantly for our purposes, it has a number of beginners resources, including <a href="https://colarusso.github.io/dm/more.html" target="_blank">a glossary</a> where much of the game play and many concepts are explained. 
    </li>

    <li>
      <a href="https://www.google.com/books/edition/The_Tyranny_of_Story_Audience_Expectatio/-nJzAgAAQBAJ?hl=en&gbpv=0" target="_blank">The Tyranny of Story: Audience Expectations and the Short Screenplay 2nd Edition</a> by Ric Beaisto. Description  
      <i>Summary based on a draft from our <a href="posts/summarize-and-question">day one template</a>.</i>
    </li>



    <!--<li><a href="">text</a></li>-->
  </ol>
  
  <!-- 
  =================================================
  
                  Preview projects

  =================================================
  --> 
  <div id="previews"></div>
  
  </div>
  <!-- END PAGE CONTENT -->
  <div class="footer">
      <span class="footer_links">
        <a href="https://mastodon.social/@Colarusso" target="_blank">Mastodon</a>
        | <a href="https://github.com/colarusso" target="_blank">GitHub</a>
        | <a href="./privacy">Privacy</a> 
        | <a href="https://sadlynothavocdinosaur.com/feed.xml">RSS</a>
      </span>
      <span class="byline">Site by David Colarusso</span>
  </div>
</div>

<script>

  /*new GreenAudioPlayer('.gap-example');
  const audio_object = document.querySelector('.gap-example  audio');

  try {
		MathJax.typeset();		
	} catch (error) {}*/
  
  (async () => {
    prompts = await loadFile('posts/POSTSLUG/prompt_template.txt');
    exported = await loadFile('posts/POSTSLUG/interactions.html');
  })()
</script>

</BODY></HTML>

