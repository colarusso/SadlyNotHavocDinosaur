<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/" xmlns:atom="http://www.w3.org/2005/Atom" >
<channel>
  <title>Sadly Not, Havoc Dinosaur: The personal website of David Anthony Colarusso</title>
  <link>https://sadlynothavocdinosaur.com</link>
  <description> I'm a big fan of lists. If there's one productivity hack worth its salt, it's the list. Create a list of discrete tasks, and check them off as you go. It's simple and it works, and although people joke about their inboxes serving as to-do lists, let's face the fact that a lot of email authors don't always put their asks front and center. Given LLMs' facility with words, I think there's something we can do about that. Last week we introduced a template to help answer emails. Today, we'll ask our LLM to figure out what an email is asking of us, produce a set of action items, and add these to a to-do list. We'll also show you how save your scratch pad to a file. </description>
  <language>en-us</language>
  <atom:link href="https://sadlynothavocdinosaur.com/feed.xml" rel="self" type="application/rss+xml" />

  <!-- ONDECK


  --> 

  <item>
    <title>Summon the Demon: Strengthen your arguments with an AI-powered devil's advocate</title>
    <link>https://sadlynothavocdinosaur.com/posts/devils-advocate/</link>
    <description>Today's template will let you summon a rhetorical sparring partner, a devil's advocate intent on challenging your assumptions. As Damien Patrick Williams has noted, the discussion of AI finds itself infused with religious language. “Religious perspectives, myth, and magic are not merely evocative lenses by which to understand the work done by algorithms and 'AI' in the present day— though they are indeed that. And they're not merely the historical underpinnings of the practices of technology in general and the dream of 'AI' in particular— though they are that, too. Rather, these elements resonate and recur throughout the past and present practice of 'AI' development—and those practices then act as new inputs, foundations, tinting lenses from and through which those systems and artifacts learn. These are ways of living in the world which don't simply exist at the margins or the periphery of our social interactions—rather they're foundational and central to the goals, the aims, the practice of these technoscientific projects, and especially 'AI.'”</description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/devils-advocate_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/devils-advocate_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/devils-advocate/</guid>
    <pubDate>Tue, 06 Feb 2024 05:00:00 GMT</pubDate>
  </item>

  <item>
    <title>What About...?: Have AI/LLMs suggest questions readers might have after reading what you've written</title>
    <link>https://sadlynothavocdinosaur.com/posts/reader-questions/</link>
    <description>One of my favorite bits of writing advice is, "let your writing breathe." That is, don't write everything in one go. Let it sit so you can come back to it with fresh eyes. It's easy to reread something you just wrote and unconsciously fill in the blanks. If you want a different perspective, you need distance or another person.  Well, maybe now there's a third option. ;) Like me, Quinten Steenhuis, with whom I co-directs Suffolk's LIT Lab, has been playing with large language models (LLMs). Recently he wrote some quick thoughts about integrating AI with law school clinical practice in which he had a number of suggestions for how to use an LLM to act as a "editor, critic, or proofreader." Last week we engaged our LLM to do some copy editing, but today I want to focus on something Quinten suggested that really jumped out at me. It jumped out because it provides a new way of accessing the perspective I mentioned above. How? By answering the question, "What questions would someone have after reading this?" </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/umm-wait.gif" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/umm-wait.gif"/>
    <guid>https://sadlynothavocdinosaur.com/posts/reader-questions/</guid>
    <pubDate>Mon, 05 Feb 2024 05:00:00 GMT</pubDate>
  </item>

  <item>
    <title>Decodable Books On-Demand: Use AI to create custom books for beginning readers</title>
    <link>https://sadlynothavocdinosaur.com/posts/decodable/</link>
    <description>My wife and I just finished editing our first book together—Ben's Frog. It's six pages long, what reading teachers call a decodable book. Think, "See Spot run." They help beginning readers practice decoding strategies for specific grapheme to phoneme patterns (e.g., how the letters "ay" make the sound /ā/). They provide readers with "books" that match what they're learning as they go, helping them build confidence. Functionally, this means a book's vocabulary is constrained by a list of "known words," or more accurately, a list of known grapheme to phoneme patterns. As the reader learns more, the list grows larger. Consequently, a reader's ability to decode/read such books is dependent on the patters they've learned, and since different curricula introduce patterns in different orders, there is no universal set of decodable books. So, early elementary teachers are often left to make their own. I know this because my wife, Jessica, teaches first grade. </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/bens_frog.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/bens_frog.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/decodable/</guid>
    <pubDate>Sun, 04 Feb 2024 05:00:00 GMT</pubDate>
  </item>


  <item>
    <title>The Elements of Interactive Style Guides: Have AI provide writing feedback based on a house style guide</title>
    <link>https://sadlynothavocdinosaur.com/posts/anger-translator/</link>
    <description>Yes, this week's theme seems to be talking to robot writing assistants while drinking coffee at a cafe. Well, that and the idea that you should feed more words into a large language model (LLM) than you ask it to output. We do this to mitigate hallucinations along with other issues. We will continue this approach with today's template, The Elements of Interactive Style Guides. Here's how it works, you highlight some text you want to "clean up," and it responds with suggestions based on a style guide provided by you. If you like, you can start a "conversation" to further refine your writing.  </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/writing_helper_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/writing_helper_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/anger-translator/</guid>
    <pubDate>Fri, 01 Mar 2024 05:00:00 GMT</pubDate>
  </item>


  <item>
    <title>Translate Legalese: An AI tool for rewriting texts in plain language</title>
    <link>https://sadlynothavocdinosaur.com/posts/legalese/</link>
    <description>Instead of feeding 5 words to a large language model (LLM) and expecting 500 (e.g., write me an essay discussing the lessons of the French Revolution), more folks should be feeding their AIs 500 words and asking them to generate 5. This funneling approach tends to mitigate hallucinations and the biases that creepin when LLM's free associate. If you're feeding in more than you expect to get out, you're looking through the wrong end of the telescope. Consequently, we've created a good number of templates that work with summarization and entity extraction. Restructuring existing text is one of the things LLMs excel at. So, today we'll ask our prompt to help turn complicated texts into plain language. </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/explaining_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/explaining_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/legalese/</guid>
    <pubDate>Thu, 29 Feb 2024 05:00:00 GMT</pubDate>
  </item>

  <item>
    <title>Magnifying Ideas with AI: In which I show you how to use AI to help write something both personal and original, bucking the assumptions that AI writing can never be personal or original</title>
    <link>https://sadlynothavocdinosaur.com/posts/maginify/</link>
    <description>Yesterday we used AI to shorten text. Today, however, we'll write a template we can use to expand text. That's right, we'll select one or two sentences and turn them into a paragraph. Here it's worth remembering some of what I said in that series' first post. I observed that I saw a lot of folks wanting to feed 5 words to AI and get out 500 (e.g., write me an essay discussing the lessons of the French Revolution) and suggested that this was like looking through the wrong end of the telescope. What people needed to be doing was feeding the AI 500 words and asking it to generate 5. In this way we could mitigate hallucinations and the like... </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/writing_partner_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/writing_partner_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/maginify/</guid>
    <pubDate>Wed, 28 Feb 2024 05:00:00 GMT</pubDate>
  </item>

  <item>
    <title>500 Characters? I'll Make It Fit!: Use AI to shorten text</title>
    <link>https://sadlynothavocdinosaur.com/posts/shorten/</link>
    <description>Confronted with a character limit, have you ever found your reply too long? If so, today's prompt template is for you. Compress your writing with the click of a button. No longer must we sign off with "I would have written a shorter email, but I did not have the time." Eat your heart out Pascal! </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/darlings_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/darlings_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/shorten/</guid>
    <pubDate>Tue, 27 Feb 2024 05:00:00 GMT</pubDate>
  </item>

  <item>
    <title>Should the USPTO ask AI for help with Pop Culture References?: How LLMs could help screen for bad-faith trademark applications</title>
    <link>https://sadlynothavocdinosaur.com/posts/uspto-llms/</link>
    <description>Recently, a company that is decidedly not DC Comics managed to acquire a trademark registration for "Harleen Quinzel" for use with various types of clothing goods. You may not recognize this name off the bat. However, do you perhaps know the name Harley Quinn? The famous DC Comics villain, whose origin story is closely tied to the Joker, has appeared in 3 major motion pictures in the last 8 years (Suicide Squad, Birds of Prey, and The Suicide Squad - and yes, Suicide Squad and THE Suicide Squad are actually two different films) and is appearing in yet another one later this year (Joker: Folie à Deux). "Dr. Harleen Quinzel" is her "real" name, the Bruce Wayne to her Batman, the Norman Osborne to her Green Goblin, the Charles Xavier to her Professor X. </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/harlequin_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/harlequin_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/uspto-llms/</guid>
    <pubDate>Mon, 26 Feb 2024 05:00:00 GMT</pubDate>
  </item>


  <item>
    <title>Your Own Personal Anger Translator: Translate angry comments into thoughtful replies in context</title>
    <link>https://sadlynothavocdinosaur.com/posts/anger-translator/</link>
    <description>Key &amp; Peele had a series of sketches built around President Obama's anger translator, Luther. The conceit of the bit was that Luther gave voice to the things Obama couldn't or wouldn't say. For example, Luther translated Obama's, "On the domestic front, I just want to say to my critics, I hear your voices, and I'm aware of your concerns," into, "So maybe if you could chill the hell out for like a second, then maybe I could focus on some shit, you know?" It was a brilliant exploration of Obama's place in the American experiment and the impossible needled he was asked to thread day in and day out. It resonated with many because they understood the righteous frustration that comes from having to conform one's outward expression to external expectations. There's something deeply cathartic about giving actual voice to that frustration, and over the years we were introduced to other translators, including Michelle, Malia, and Hillary's. So, I thought it might be interesting to see if we could harness a Large Language Model (LLM) to provide anyone with a personal anger translator. However, there's a twist. This translator would serve as Luther in reverse. That is, it would take an unvarnished blunt and imprudent expression of raw emotion and shape it into a more palatable variant. I'm told that sometimes it can be helpful to write out a snide reply or "subtweet" without the intention of hitting send just to work through your rage. Now with modern technology, you can write that brutally honest reply and have it "translated" with the click of a mouse—mechanized catharsis on demand.  </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/luther-obama.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/luther-obama.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/anger-translator/</guid>
    <pubDate>Fri, 23 Feb 2024 05:00:00 GMT</pubDate>
  </item>

  <item>
    <title>Is This Good?: Extract sentiment from social media posts, label each, and structure output as JSON</title>
    <link>https://sadlynothavocdinosaur.com/posts/is-this-good/</link>
    <description>To the extent this week's templates have shared a theme, it has been analyze and structure. So, it was only a matter of time before we ran into a use case built around sentiment analysis. Today, we'll build a template that allows you to select the text of several social media posts and label each posts' sentiment while creating a JSON object to hold data about each post, including this new sentiment label. Customarily, this sort of analysis is used on social media to help product or brand management folks stay abreast of public sentiment, or to feed algorithmic stock traders—people like company, buy, people unhappy with company, sell. ;) </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/sentiments_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/sentiments_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/is-this-good/</guid>
    <pubDate>Thu, 22 Feb 2024 05:00:00 GMT</pubDate>
  </item>

  <item>
    <title>Flag Logical Fallacies with a Browser Extension: Have AI read a webpage and flag logical falacies</title>
    <link>https://sadlynothavocdinosaur.com/posts/flag-fallacies/</link>
    <description>I'm not an AI doomer in the sense that I don't think much about p(doom)—the probability that AI will end humanity. I'm much more worried about megacorps exploiting AI for profit at the expense of the marginalized. Which is to say, I'm more concerned about the world of RoboCop than I am of the Terminator. I am, however, sympathetic to those who worry that AI-generated misinformation could supercharge the asymmetry at the center of Brandolini's Law, which states, "The amount of energy needed to refute bullshit is an order of magnitude bigger than that needed to produce it." There's a lot to worry about in a world where the cost of BS production drops nearly to zero. So, I thought I'd explore what could be done for the side of the angles. Today's template aims to spot and flag logical fallacies based on the text of a webpage—like an AI fact checker of sorts.</description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/bingo_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/bingo_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/flag-fallacies/</guid>
    <pubDate>Wed, 21 Feb 2024 05:00:00 GMT</pubDate>
  </item>

  <item>
    <title>TL;DR LLM: Blurb a webpage for social media</title>
    <link>https://sadlynothavocdinosaur.com/posts/tldr-post/</link>
    <description>Functionally, today's template, which creates a short summary of a webpage for sharing on social media, is a special-use adaptation of our very first prompt template. However, I would like to use this familiar task to explore two new ideas. First, the fact that you can create special-use versions of existing templates, and second, how one can use the CHAT behavior to do more than question content. </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/robo_social_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/robo_social_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/tldr-post/</guid>
    <pubDate>Tue, 20 Feb 2024 05:00:00 GMT</pubDate>
  </item>


  <item>
    <title>Narrative Quanta: LLMs as RPG Building Blocks Generate the outcome of a scene for a role-playing game</title>
    <link>https://sadlynothavocdinosaur.com/posts/rpg-quanta/</link>
    <description> Over the course of this series I've come to embrace training simulations as a promising use case for large language models (LLMs). Such use recasts many of an LLM's traditional weaknesses as strengths. A tendency to make things up is after all an asset when performing improv. When I introduced simple simulations, I promised we'd eventually get to more advanced ones. See What if Members of Talking Professions Could Log Time in Simulators Like Pilots? To date, we've simulated the first meeting between a public defender and their client as well as a law professor engaging a student in Socratic dialogue. These simulations were a bit shallow, however. For one thing, they presented an unending unchanging dialogue. One reader after starting the simulated client meeting observed, "I can't figure out how to make it end." My suggestion was that they say goodbye to their client and "exit," by which I meant, "stop typing." </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/dragons_and_desk_jobs_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/dragons_and_desk_jobs_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/rpg-quanta/</guid>
    <pubDate>Mon, 19 Feb 2024 05:00:00 GMT</pubDate>
  </item>


  <item>
    <title>2.B, or Not 2.B? Have an AI answer multiple choice and true or false questions based on a reading assignment</title>
    <link>https://sadlynothavocdinosaur.com/posts/answer-questions-with-context/</link>
    <description> Yesterday, inspired by GPT-4 passing the bar exam, we tried getting an LLM to some reading questions about Hawkins v. McGee. The LLMs didn't do so hot, only getting 40-47% of the questions right. So, what was missing? Remember, way back in the first post where we said, "If you want an LLM, or the man on the street, to summarize a text, have them read it first." Well, it turns out, if you want an LLM to answer questions about a text you should have them read it first. 😜 Yesterday's template was divorced from context. For example, one of the questions was "What was the court's decision regarding the defendant's requests for instructions?" In isolation, there's no way of knowing what decision the question is asking about. So, today we'll be including that context by making the text part of our prompt. For the record, using gpt-3.5-trubo-16k and the template below I was able to get 4 out of 5 on Tuesday's questions, and 8 out of 10 on Wednesday's questions. That's a solid 80%. When I switched the model to gpt-4, it scored 5/5 and 9/10 respectively. That's 93%! Just to remind you, yesterday's template got 40% and 47%. I think there's something to be said for context.</description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/robot_bubble_sheet_03_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/robot_bubble_sheet_03_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/answer-questions-with-context/</guid>
    <pubDate>Fri, 16 Feb 2024 00:00:00 GMT</pubDate>
  </item>


  <item>
    <title>A Hawk from a Handsaw: Have an AI "guess" the right answers for multiple choice and true or false questions</title>
    <link>https://sadlynothavocdinosaur.com/posts/answer-questions/</link>
    <description>You may have heard that GPT-4 passed the bar exam, and though I think this fact tells us more about the bar exam than GPT-4, it's worth thinking about how it does this. As we've noted, large language models (LLMs) are sentence completion machines. They guess the next word based on what they've seen in their training data. They can answer questions because their training data contains questions and answers. They can "answer" questions not in their training data because there are patters to how folks answer questions, patters it has "learned." Of course, if a question-answer pair was in its training data, that doesn't hurt, and with these models being trained on broad swaths of the internet, they very well might be in there. Today and tomorrow, we're going to do a little experiment. It turns there was an ulterior motive behind Tuesday and Wednesday's posts. Yes, there is a method to my madness. Those posts contain a set of questions and answers we can feed into today's template. Today we are seeing if we can get an LLM to correctly answer those questions. Spoiler alert: today won't go so well. Double spoiler alert: tomorrow will go better. Homework assignment: see if you can guess how we'll make that happen. </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/robot_bubble_sheet_02_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/robot_bubble_sheet_02_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/answer-questions/</guid>
    <pubDate>Thu, 15 Feb 2024 00:00:00 GMT</pubDate>
  </item>


  <item>
    <title>True or False? Use AI to draft true or false questions based on a reading assignment</title>
    <link>https://sadlynothavocdinosaur.com/posts/create-true-false-questions/</link>
    <description>When counting to 50 even a super-short post which replaces "multiple choice" with "true or false" counts as a post, true or false? The answer is TRUE! This week started with a barn-burner in which I wrestled with how best educators should work to address a changing world, and yesterday I showed off how you can use LLMs as a time-saver when creating multiple choice questions. Today, we're taking on true or false questions. </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/true_false_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/true_false_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/create-true-false-questions/</guid>
    <pubDate>Wed, 14 Feb 2024 00:00:00 GMT</pubDate>
  </item>

  <item>
    <title>All of the Above: Use AI to draft multiple choice questions based on a reading assignment</title>
    <link>https://sadlynothavocdinosaur.com/posts/create-multiple-choice-questions/</link>
    <description>I began my professional career as a high school teacher, and I'm a big fan of formative assessment. So, when I returned to the classroom as a student for law school, I found its nearly exclusive reliance on summative assessments not only frustrating but perplexing. Such an inballance goes against nearly everything I learned during my Master's in Education. Now, I don't think a prompt template that makes reading questions based on the text of a reading assignment is by any means a magic fix, but I am intrigued by the idea that we can use technology to help improve instruction by making it easier for teachers to provide more formative assessments. Obviously, I'm a fan of simulations in part because of the promise they offer in this arena. But it's important not to overlook the "classics." Today's template lets one create a set of multiple-choice questions based on the text of a reading assignment. </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/robot_bubble_sheet_01_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/robot_bubble_sheet_01_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/create-multiple-choice-questions/</guid>
    <pubDate>Tue, 13 Feb 2024 00:00:00 GMT</pubDate>
  </item>


  <item>
    <title>If a 3L Can Automate Law Students, I Can Automate Law Profs—Robo Socrates Lives! A law school instructor shows you how to get AI to brief cases, explain them to a 5yo, play the gunner, and conduct a Socratic dialogue all for FREE!</title>
    <link>https://sadlynothavocdinosaur.com/posts/socrates-lives/</link>
    <description>Last week I couldn't escape the story of Bradley Neal, a 3L who has built a gen AI tool that creates case briefs and answers questions about cases. I love the story, and I love the tool. So much so I spent the weekend recreating most of its functionality. Like Mr. Neal's tool, mine can create case briefs, explain cases in plain language, and directly answer questions about a case. These are common tasks for law students, but I didn't stop there. I also created a bot capable of acting like a law school professor, a bot that will grill you using the Socratic method. That's right, it's an on-call simulator. I call the suite of tools The Paper Chase 2.0. You can see the results here, or build and customize your own version for FREE by following the instructions below.  </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/socrates_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/socrates_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/socrates-lives/</guid>
    <pubDate>Mon, 12 Feb 2024 00:00:00 GMT</pubDate>
  </item>

  <item>
    <title>This Day in History: Generate fun "facts" for this day in history</title>
    <link>https://sadlynothavocdinosaur.com/posts/this-day-in-history/</link>
    <description>As you know, we can seed a prompt with today's date to interesting effect, but whereas last week we used the date to produce poetry, this week we're looking to learn some fun "facts." I've placed "facts" in scare quotes because as we know, large language models (LLMs) are prone to hallucinations. Below I'll share a prompt that asks an LLM to share a significant historical event from this day in history. I like to imagine using this template is a little like playing the game Bluff the Listener, a regular segment on the radio show Wait, Wait, Don't Tell Me.... Here's how it's introduced every week, "Our panelists read three stories about something new in the world of [that week's topic], only one of which is true." A caller contestant must guess the true story to win. So, dear reader, when reading your daily fun "fact," it might be "fun" to follow it up with a Google search. Today, however, things are looking pretty good. Here's an output I got for February 9th. I apologize for asking the template to format the output as a social media post. 😬 </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/beatles.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/beatles.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/this-day-in-history/</guid>
    <pubDate>Fri, 9 Feb 2024 00:00:00 GMT</pubDate>
  </item>

  <item>
    <title>Old-School Automation: Complete a "form letter" without engaging an LLM</title>
    <link>https://sadlynothavocdinosaur.com/posts/form-letters/</link>
    <description>It's worth taking at least one day to explore the use of the LIT Prompts extension minus the use of an LLM. As it turns out, in making a browser extension that produces templatized reusable LLM prompts, I first had to create a tool capable of making standard fill-in-the-blank templates. We can use both predefined variables and user inputs, meaning these templates can get pretty sophisticated. Today we'll construct a simple form letter. The letter will fill in today's date and ask for a recipient and sender. You should rework the body of the letter to serve your needs. For what it's worth, when I use the extension to produce text without engaging an LLM, it's usually for a bit of boilerplate, like a paragraph about how someone can see my calendar and book a time. My hope is that in working through the form letter, similar ideas will come to mind. So, let's build something! </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/movable_type_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/movable_type_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/form-letters/</guid>
    <pubDate>Thu, 8 Feb 2024 00:00:00 GMT</pubDate>
  </item>

  <item>
    <title>The Dream of Universal Translation: Translate text into English then translate your reply into the original language</title>
    <link>https://sadlynothavocdinosaur.com/posts/translate-selected/</link>
    <description>The variety of human language has long been cast as an impediment to communication rather than a laboratory of descriptive experiments, each providing a unique vantage point on the human condition. In fairness, however, absent translation, the insights gained from such experiments would remain inaccessible to all but a fraction of humanity. The fear that insights from the speakers of one language will crowd out those of others is a chief concern of those who look critically on the training of Large Language Models (LLMs). Given too much weight in an LLM's training, the ideas obsessed over by the speakers of one language threaten to dominate those less commonly expressed. However, given sentence completion machines (LLMs) are trained on texts which surely included many sets of translations, they also offer the promise of translation, the promise of understanding. </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/hello.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/hello.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/translate-selected</guid>
    <pubDate>Wed, 7 Feb 2024 00:00:00 GMT</pubDate>
  </item>

  <item>
    <title>Taming Texts or: How To Turn Unstructured Prose Into Structured Data - Diagram selected sentence, output JSON</title>
    <link>https://sadlynothavocdinosaur.com/posts/diagram-sentence/</link>
    <description>A good deal of social science, and empirical legal work for that matter, relies on the parsing of large texts. Say you want to explore how often a court sides with the "government" over "industry," and more to the point, when and how much money is involved in such cases. Unless someone else has done the work, there isn't a spreadsheet you can consult. Someone will have to read through all of that court's cases and figure out who was who, who won, and how much money was involved. You might be able to make some progress with something like regular expressions, but unless the text is very regular in its presentation, you'll miss things. Regular expressions let you search for well-defined patterns in text. Instead of saying, "find 867-5309," you can say, "find me all three-digit numbers adjacent to a dash followed by a four-digit number. (i.e., find the phone numbers in this text, not just a single phone number)." The problem is, what if the there's a phone number of the form 555.5555? That darn pretentious period can break everything. So, a more robust method is often called for. The point being, it can be useful to transform prose into something like a spreadsheet, what is sometimes called structured data. Such data is easy for computers to consume. That is, it's easy to sort, count, and connect. </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/robo_teacher_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/robo_teacher_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/diagram-sentence/</guid>
    <pubDate>Tue, 6 Feb 2024 00:00:00 GMT</pubDate>
  </item>

  <item>
    <title>What if Members of Talking Professions Could Log Time in Simulators Like Pilots? Craft simple training simulations with "AI actors"</title>
    <link>https://sadlynothavocdinosaur.com/posts/simple-training-sims/</link>
    <description>As an experiential educator, I firmly believe experience is an excellent teacher. The question I have to answer is how best to introduce students to that experience. Some of my favorite experiences as a law student centered around simulations, practicing direct and cross-examination with actors, negotiating on the behalf of non-existent clients. When it's impractical, unethical, or dangerous to learn by doing in the real world, we fall back on simulations. When robust simulations are out of reach, we focus on practicing smaller parts of the experience. Sometimes, breaking things down into smaller tasks like this is by choice, it's a way to hone individual skills, but sometimes there really is no substitute for putting it all together. My favorite simulations were those where a professional or student actor was hired to play a role, but as you can imagine such simulations are hard to pull off. Mostly, they exist as capstone projects (e.g., a moot court exercise where you try a case at the end of the semester). Large Language Models (LLMs) offer us the ability to create simple easy-to-implement simulations for those who need to practice having conversations. I really like simulations as a use case for LLMs because it doesn't matter if they hallucinate, and to the extent they regurgitate societal biases they present openings to unpack such biases and how they will affect our practice. </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/robot_actor.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/robot_actor.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/simple-training-sims/</guid>
    <pubDate>Mon, 5 Feb 2024 00:00:00 GMT</pubDate>
  </item>


  <item>
    <title>A Pome for the Moment: Turn the time of day into a poem</title>
    <link>https://sadlynothavocdinosaur.com/posts/time-poem/</link>
    <description>I'm sitting down to write this post the day before it will go live, but before I do so, I check the time. &quot;In February's chill, at four twenty-two,/ Thursday's dusk whispers winter's adieu.&quot; This was generated by today's prompt template at 4:22pm on Thursday February 1st. It's a simple prompt, using the month, day, and time to write a short pome. I rather like it. As we've seen before, the LIT Prompts extension comes preloaded with some variables. Like last Friday's template, I thought it would be nice to seed a poem with some of these variables, namely the month, day and time. I did not, however, say what hemisphere I'm in as part of the prompt. I happen to be typing this from my home in New England. So, the assumption that it is both chilly and near dusk ring true. It's only the start of February, but pitchers and catchers report for spring training in two weeks. So, I'll allow &quot;winter's adieu.&quot; Had I been in New South Wales, however, this pome would strike me as out of season. Of course, this shouldn't come as a surprise given what we know about how LLMs encode and reflect the assumptions found in their training data. It would seem, most of those texts came from the northern hemisphere. </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/clock_store_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/clock_store_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/time-poem/</guid>
    <pubDate>Fri, 2 Feb 2024 00:00:00 GMT</pubDate>
  </item>

  <item>
    <title>Follow This One Trick to Write Great Headlines: Produce a collection of possible compelling headlines based on the text of an article</title>
    <link>https://sadlynothavocdinosaur.com/posts/headlines/</link>
    <description>To be clear, the above title is a joke. It's also clickbait. ;) There isn't one trick to writing a great headline partly because folks can't agree on what makes a great headline. Is a great headline one that grabs attention at all cost (unsavory publishers) or one that properly sets expectations (mild-mannered readers)? Either way, I'll show you how to us an LLM to produce headlines based on a text, and then I'll suggest ways you can tune it better fit your needs. I'll even show you how to export your workflow to make a headline generation tool. Remember, with great power comes great responsibility. </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/robot_pitch.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/robot_pitch.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/headlines/</guid>
    <pubDate>Thu, 1 Feb 2024 00:00:00 GMT</pubDate>
  </item>

  <item>
    <title>Add Email Asks to My To-Do List: Find the "asks" in an email; produce a bulleted  list of same; add these to a to-do list; save to a file</title>
    <link>https://sadlynothavocdinosaur.com/posts/email-to-do/</link>
    <description>I'm a big fan of lists. If there's one productivity hack worth its salt, it's the list. Create a list of discrete tasks, and check them off as you go. It's simple and it works, and although people joke about their inboxes serving as to-do lists, let's face the fact that a lot of email authors don't always put their asks front and center. Given LLMs' facility with words, I think there's something we can do about that. Last week we introduced a template to help answer emails. Today, we'll ask our LLM to figure out what an email is asking of us, produce a set of action items, and add these to a to-do list. We'll also show you how save your scratch pad to a file. </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/email_to_do_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/email_to_do_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/email-to-do/</guid>
    <pubDate>Wed, 31 Jan 2024 00:00:00 GMT</pubDate>
  </item>

  <item>
    <title>Give Me the Recipe, Not an SEO-Motivated Short Essay</title>
    <link>https://sadlynothavocdinosaur.com/posts/recipe/</link>
    <description> It has been observed that the rise of search engine optimization (SEO) has lead online publishers to bury recipes and other useful nuggets of information below a pile of what looks to be lengthy essays. The idea being that such keyword-rich long-form articles will rises to the top of search results, driving traffic and ad revenue. The problem with this is that you and I dear reader are forced to sift through a mountain of prose to find what we're really looking for—the recipe. Today, we'll use an LLM and the LIT Prompts browser extension to find the proverbial needle in the haystack. We'll get the extension to return the recipe and only the recipe.  </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/pie_crust.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/pie_crust.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/recipe/</guid>
    <pubDate>Tue, 30 Jan 2024 00:00:00 GMT</pubDate>
  </item>


  <item>
    <title>I Turned My Scholarly Papers Into Chatbots so People Don't Have To Read Them 🤞: Turn scholarly papers into chatbots so people don't have to read every word</title>
    <link>https://sadlynothavocdinosaur.com/posts/papers2bots/</link>
    <description>If you want to start chatting with my papers, click here. I prepaid for some "AI" time. So, chat away while the getting is good. Otherwise, let's take a moment to talk about how we got here. Last week we kicked things off by summarizing and questioning webpages. We closed the week by showing you how to export our templates to create a free-standing web app/webpage. Today, we'll take these add in some existing texts, and produce something new. The 🤞 in the title above can be read roughly as, "what could go wrong?" My hope is readers will treat the bot's output they should any secondary source. That is, if they see anything that piques their interest, they should check the primary source for confirmation. </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/talking_book_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/talking_book_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts//</guid>
    <pubDate>Mon, 29 Jan 2024 05:30:00 GMT</pubDate>
  </item>


  <item>
    <title>Flip a Poem; Roll an "App": Turn the outcome of a coin flip into a poem and package this as an "app"</title>
    <link>https://sadlynothavocdinosaur.com/posts/coinflip-poem/</link>
    <description>This week we've used LLMs to talk with texts, reply to emails, and figure out unfamiliar phraseologywith input provided by the browser. In future posts, we'll tackle more complex prompt patterns, but we'll also take advantage of LIT Prompt's virtual dice and export functionality to make some really interesting interactions you can share or save for later. Alas, before we run, we must walk, and before we walk, we must crawl. To get our bearings, today's prompt finds us flipping a virtual coin, writing a poem about the flip's outcome, and packaging the whole thing up as a "web app." By way of foreshadowing, LIT Prompts comes preloaded with a virtual coin, not to mention 4, 6, 8, 10, and 20-sided dice. 🤔 I wonder what could be coming? </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/coinflip_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/coinflip_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/coinflip-poem/</guid>
    <pubDate>Fri, 26 Jan 2024 04:00:00 GMT</pubDate>
  </item>


  <item>
    <title>You Can't Be Neutral on a Moving Train: Define a selected word, phrase, idiom, or initialism given the context of the webpage on which it is found</title>
    <link>https://sadlynothavocdinosaur.com/posts/define-words-in-context/</link>
    <description>If I had a motto, it might be "context matters." Except, I'm resistant to picking a singular guiding principle because, well... context matters. 😉 Earlier in the week, we wrote a template to provide definitions for words we highlighted in the browser, but we found when kicking the tires that sometimes this feel down when dealing with terms of art or initialisms claimed by competing collections of words. What was lacking in these instances was context. So, today we'll add context from the active page to the prompt template. Before we get there, let's talk context more broadly. </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/dictionary_train_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/dictionary_train_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/define-words-in-context/</guid>
    <pubDate>Thu, 25 Jan 2024 05:30:00 GMT</pubDate>
  </item>

  <item>
    <title>I'm Sorry, Dave Can't Do That: Use the text of an email to draft a polite reply declining any request(s)</title>
    <link>https://sadlynothavocdinosaur.com/posts/decline-requests</link>
    <description>With apologies to Kubrick and Clarke, at least I can say I held out two full days before alluding to a killer AI. That's also how long I resisted sharing a use case in which we use an LLM to help write something. There's a great deal to be said about authorship in the age of ChatGPT, and perhaps we'll explore this more in future posts. For the moment, however, let me provide a framing I find useful. It starts by recognizing that context matters and that writing itself is not one task. The production of written work involves the application of multiple overlapping tasks. Consider the traditional roles found in a newsroom (e.g., editors in chief, assignment editors, writers, fact checkers, copy editors, and the like). When delegating any of these tasks, to a human or otherwise, it is important to have in mind what role(s) we are delegating and why. Putting one's name to a document means different things in different contexts. Just ask the paralegal who writes all their partner's "first drafts." For instructors worried about the use of AI by their students, I suggest they name the role(s) an assignment is looking to assess. This allows the instructor and student to properly evaluate whether or not the use of this or that tool is acceptable. If handwriting is among the matters being assessed, a word processor is out. Copy editing? This may or may not exclude the use of spell check. What about grammar check? If, however, there is no instructor, and the question is left to us alone, we have to be honest with ourselves about the job at hand.   </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/robo_shrug_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/robo_shrug_square.png"/>
    <pubDate>Wed, 24 Jan 2024 12:00:00 GMT</pubDate>
  </item>

  <item>
    <title>A Rose by Any Other Name: Define a selected word, phrase, idiom, or initialism on a webpage with AI</title>
    <link>https://sadlynothavocdinosaur.com/posts/define-words</link>
    <description>I Google the definitions of words with surprising frequency, mostly as part of my writing process. As a dyslexic, it's mostly a backstop for spellcheck. After it has reassured me that I'm only using real words, I tend to use text-to-speech to read what I've written. If a word sounds off, I look it up to make sure it's really the word I intended. It's also good for double checking homophones (e.g., I thought I spelled "discrete", but this seems to be "discreet"). After this idiosyncratic use, I find myself using search to discover the meanings of opaque anacronyms and initialisms, usually when I wonder off into some unfamiliar part of cyberspace. What does this person mean when they say "SOP?" Is that business speak? After wading through alphabet soup, the next most common hunt for meaning I find myself on is that of an old looking to understand the kiddos. How cringe? And I have to say, search has worked for me, but sometimes it takes some high-level Google-fu to track down what I'm looking for. What if I could just select a word or phrase, click a button, and get a definition be it word, idiom, or initialism? Well, I'm happy to say today's prompt template does just that.  </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/dictionary_square.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/dictionary_square.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/define-words</guid>
    <pubDate>Tue, 23 Jan 2024 06:40:00 GMT</pubDate>
  </item> 

  <item>
    <title>Using AI to Distill and Question Texts | Summarize and question the contents of a webpage from within the browser</title>
    <link>https://sadlynothavocdinosaur.com/posts/summarize-and-question</link>
    <description>I've started seeing variations on the following, "Sure, I played with ChatGPT when it came out, but I don't really get what the big deal is. You can't trust what it tells you, and it's a pretty mediocre writer." These are valid criticisms, but if you stop there, it's clear you've only experienced a narrow set of what these tools can do. When I speak of "these tools" I'm referring to a class of tools properly known as Large Language Models (LLMs). Most folks' first encountered these tools under the guise of a chatbot, but they are NOT general purpose thinking machines. LLMs are sentence completion engines. Their replies aren't based on any knowledge of the world other than that contained in the co-occurrence of words in their training data. In a very real way, an LLM is "spicy autocomplete." Like machine learning (the previous generation of tech to wear the AI moniker), LLMs are prediction machines. Give them a "prompt" and they predict the most likely set of words given their training data. Prompts are what we call the text on which they build. Feed an LLM a prompt, and it will return a plausible-sounding follow-up. "Four score and seven..." might return "years ago our fathers brought forth..." because the Gettysburg Address was in the training data, and outside of quoting it, when else do people talk like that? If you hear someone say "Four score and seven..." what would you guess their next words would be? </description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/text_distillery.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/text_distillery.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/summarize-and-question</guid>
    <pubDate>Mon, 22 Jan 2024 12:00:00 GMT</pubDate>
  </item>
  
  <item>
    <title>50 Days of LIT Prompts: Learn prompt engineering through doing with new prompt patterns every weekday for 10 weeks</title>
    <link>https://sadlynothavocdinosaur.com/posts/50-days-of-lit-prompts</link>
    <description>Every weekday for the next 10 weeks, I'll update this page with new prompt patterns and invite folks to play with them inside LIT Prompts. We'll be plugging into the technology that runs tools like ChatGPT, giving you a level of control that most people don't see. You won't have to do any "coding," but we will think like coders. I'm still suspicious of the term prompt engineering, esp. when used as a job title. The idea that an entire job could be built around "talking" to an AI seems a bit too loosey goosey. So, we'll try to introduce some rigor. We'll aim to think about workflows and systems where writing prompts is just part of a larger endeavor. You'll be supported by the fact that LIT Prompts lets you produce reusable interconnecting prompt templates. This will let us build upon what we learn and improve our practice over time. We'll explore the promise and perils of this new technology while you build custom interactions/workflows. Plus, I'm pretty sure we'll have fun along the way.</description>
    <enclosure url="https://sadlynothavocdinosaur.com/images/50-days/lets_build.png" type="image/png"/>
    <media:thumbnail url="https://sadlynothavocdinosaur.com/images/50-days/lets_build.png"/>
    <guid>https://sadlynothavocdinosaur.com/posts/50-days-of-lit-prompts/</guid>
    <pubDate>Thu, 19 Jan 2024 17:00:00 GMT</pubDate>
  </item>

  <!-- Additional items here -->

</channel>
</rss>
